{"meta":{"version":1,"warehouse":"4.0.1"},"models":{"Asset":[{"_id":"themes/butterfly/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/pics/default_top_img.png","path":"img/pics/default_top_img.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/pics/index.png","path":"img/pics/index.png","modified":1,"renderable":1}],"Cache":[{"_id":"source/about/index.md","hash":"b611d3ee3b86da446ec9a96e561f2a851848f4c7","modified":1656999945616},{"_id":"source/_posts/Hexo常用命令.md","hash":"c7c62d48790e0997d1bdc196cb1b123175412af1","modified":1657289087124},{"_id":"source/photo/index.md","hash":"3178df88247ccf65693e2c5d8eb6a20e9475d638","modified":1656999055790},{"_id":"source/categories/index.md","hash":"da42992c828251fd8e707d32304dca07ed2f9073","modified":1656915370000},{"_id":"source/link/index.md","hash":"685105fad8bab7c83fcc357b749482186d7c6835","modified":1656908202000},{"_id":"source/photo/camera/index.md","hash":"619ce328777197bfa183d430fb2f73d05033b876","modified":1656999292251},{"_id":"source/_posts/深度学习-相似度点选.md","hash":"4b8ff7b74e08a6717a0c6b0117c8cfc841607824","modified":1658284492513},{"_id":"source/tags/index.md","hash":"a2ed06804562e4967243b69f2156e87e2931438c","modified":1656915394000},{"_id":"themes/butterfly/.github/stale.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1657805826740},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/bug_report.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1657805826745},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/config.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1657805826743},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/feature_request.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1657805826746},{"_id":"themes/butterfly/.github/workflows/publish.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1657805826742},{"_id":"themes/butterfly/README.md","hash":"f0e25045d220f3457fc00577928a1a17b9cae2d3","modified":1656900130000},{"_id":"themes/butterfly/README_CN.md","hash":"7824e73a3f5c626ff00d23dfeb4d256a784c330f","modified":1656900130000},{"_id":"themes/butterfly/LICENSE","hash":"c8bc7df08db9dd3b39c2c2259a163a36cf2f6808","modified":1656900130000},{"_id":"themes/butterfly/_config.yml","hash":"2729d475843406104b32d0e16cd011276bdef4a6","modified":1656900130000},{"_id":"themes/butterfly/package.json","hash":"b128a4d4ad3bb4f78a569a0ddd2010430a10d690","modified":1656900130000},{"_id":"themes/butterfly/plugins.yml","hash":"a9f927f7005aa22811017242fff42b1510865549","modified":1656900130000},{"_id":"themes/butterfly/languages/default.yml","hash":"335731ef259a3cec2499a2d5b050025ff4bdc608","modified":1656900130000},{"_id":"themes/butterfly/languages/en.yml","hash":"a96ab1bbe74e99ca2e4d67da9d83f442eb9b73af","modified":1656900130000},{"_id":"themes/butterfly/languages/zh-CN.yml","hash":"cebc5eb343cc5e6e46751a60011eb010afd04edf","modified":1656998272868},{"_id":"themes/butterfly/languages/zh-TW.yml","hash":"dcb10d62249bb149af8ad78db3ee6e342c6d6be7","modified":1656900130000},{"_id":"themes/butterfly/layout/index.pug","hash":"648dcbdb3d145a710de81c909e000e8664d2ac9c","modified":1656900130000},{"_id":"themes/butterfly/layout/category.pug","hash":"bf979aec88d78b644fc5d31518f8679ad7625792","modified":1656900130000},{"_id":"themes/butterfly/layout/page.pug","hash":"bf2d6c6d2d156777b55292e51be02b0b3acf0af8","modified":1656900130000},{"_id":"themes/butterfly/layout/archive.pug","hash":"115fa5ee8864e5c97549eff91a17c66101d724ab","modified":1656900130000},{"_id":"themes/butterfly/layout/tag.pug","hash":"4bb5efc6dabdf1626685bf6771aaa1467155ae86","modified":1656900130000},{"_id":"themes/butterfly/layout/post.pug","hash":"fdbb508b5e6dec30fb8753c5a7fdd494410c4fc0","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/404.pug","hash":"aace9ddff469de4226e47a52ede1c81e66d66d5c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/additional-js.pug","hash":"ddea99847fd41323f183cd0c9dae3174c586f5b3","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head.pug","hash":"1d0f1b84be352862046e780800d696e80ef1cdd1","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/footer.pug","hash":"8715948b93e7508b84d913be1969b28c6b067b9b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/layout.pug","hash":"3d95525a6d809be2f2a1cd6b33d3b7ecc0457d62","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/pagination.pug","hash":"bb1847f45e713cc88b1c0a97035ec01f0209c995","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/sidebar.pug","hash":"4f41fc46410e1e3018ff87e1d1a5c28be7258119","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/404.js","hash":"f1d1c378356b776e9b2a8411e6dca88dc8c3245c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/rightside.pug","hash":"205562ec188bfba5686c51af77486550d0927df5","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/cdn.js","hash":"8e6f0677c190d44c64222054e2e7c065fc6c4802","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/comment.js","hash":"176332aa4d01728d0bd084e9b02c60167dc307dd","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/init.js","hash":"b3e05e3440b078f57391c113d6b0c8ecff112720","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/stylus.js","hash":"218add7e9b39b6fb6e69921abb9e44891a6cc3ce","modified":1656900130000},{"_id":"themes/butterfly/scripts/events/welcome.js","hash":"b92cc4648cfe5fb28c58943727823d1178b73a4a","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/button.js","hash":"44cca49ddc76921bb455465ef912cab46c993cef","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/hide.js","hash":"e01a3967e5884881bab858b11635457df412de80","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/flink.js","hash":"3ba7677969ff01fab06fc6713455ddc6861f0024","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/gallery.js","hash":"6d4cd2393945a9316339351cab588265f5c18d73","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/inlineImg.js","hash":"7641adb0d520c5ff29dd36fc1fb8617c52ecc9fb","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/mermaid.js","hash":"fd683ccc090db3122d77c7ee73e8d35dc8735ee3","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/label.js","hash":"551f1b8edc973bd8afc5cce2eae546f002fa84c3","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/note.js","hash":"56a5d41487d74654b75305c5325167a116495900","modified":1656900130000},{"_id":"themes/butterfly/scripts/filters/post_lazyload.js","hash":"5fd6c9659262dc8f61d87866d0417fd534292c88","modified":1656900130000},{"_id":"themes/butterfly/scripts/filters/random_cover.js","hash":"6c3b7d0874fa499800a4fd49894c481b05ec750c","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/tabs.js","hash":"08ea00791bd4738952234cb5d8360e119df6f875","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/aside_archives.js","hash":"4f712b4ea383b59a3122683db1d54c04a79ccc5d","modified":1656900130000},{"_id":"themes/butterfly/scripts/tag/timeline.js","hash":"4c7056d3cd56f10bd209d2ba4d3cc2027aad1440","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/aside_categories.js","hash":"376e1884ea764404c38b1e73b16de0358ece519e","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/page.js","hash":"c07efb04120914363b8de2c276ac5783b82db776","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/inject_head_js.js","hash":"c445140fa16f19bf5fb617fa735504e7799d4d42","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/findArchiveLength.js","hash":"db4f5971c27f49a4cb47d34729f4ddf9919d392b","modified":1656900130000},{"_id":"themes/butterfly/scripts/helpers/related_post.js","hash":"83bfb16ab8d440be04e1b1f889f6affa7ad65a67","modified":1656900130000},{"_id":"themes/butterfly/source/css/index.styl","hash":"c7924868adcb046b46498626a9223c7a7b3f2e30","modified":1656900130000},{"_id":"themes/butterfly/source/css/var.styl","hash":"584ef7b18d5e677eb2e62f9b139097d3b714a993","modified":1656900130000},{"_id":"themes/butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1656900130000},{"_id":"themes/butterfly/source/js/main.js","hash":"0b673b89d24b78b8544cc0e048953e6dcba3e9bf","modified":1656900130000},{"_id":"themes/butterfly/source/js/tw_cn.js","hash":"4db1170be7a9360e2c5399d281b979da730df2a3","modified":1656900130000},{"_id":"themes/butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1656900130000},{"_id":"themes/butterfly/source/js/utils.js","hash":"fdb9e5b38f076953a2431b8f682388b030694b55","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/header/index.pug","hash":"6f489b24f06578440f18b629db56c810f00f8c3f","modified":1656900130000},{"_id":"themes/butterfly/source/img/favicon.png","hash":"c8171b028fee71af81ff36b84a86f132119cefc7","modified":1657291886632},{"_id":"themes/butterfly/layout/includes/header/menu_item.pug","hash":"ca8bcd90ad9467819330bfe7c02b76322754bccf","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/header/nav.pug","hash":"a9e56b1c41bf327859b0a7bcb8e72b458bd851b2","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/header/post-info.pug","hash":"37e407cb98398f64bf2ca3cb5300f671d6a42dad","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/header/social.pug","hash":"631ec7000fd4d6cfa2de118ee02ad8a42ffb34f5","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/loading/loading-js.pug","hash":"2e1ab0c2ca59a1ff5a5ba9b6ef60f3e34af5430c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/loading/loading.pug","hash":"dd8e6813976be64e80eba6562b54e74527ab306d","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/mixins/article-sort.pug","hash":"971038debf539333b1687b4a1d87cf4fc965a846","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/mixins/post-ui.pug","hash":"7a7061f3d5da043ea81f625893e1c5cace2c931f","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/Open_Graph.pug","hash":"07380718ed3af19a7e64b30e8c13726fe5983947","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/analytics.pug","hash":"c1e45d4d0bd905ddcd2282de4fe89be92e67847d","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/config.pug","hash":"8a3f9e674b44e6a92d4df22baca65d9d30007dc3","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/config_site.pug","hash":"bd5dd5452e28a4fe94c3241a758ec6f4fdb7a149","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/noscript.pug","hash":"72efaa09ff60843567458bd54152e06f0cb2757e","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/google_adsense.pug","hash":"f29123e603cbbcc6ce277d4e8f600ba67498077c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/preconnect.pug","hash":"fc3e67e5ae4774d9e89964ba96beed28f34ee8f0","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/pwa.pug","hash":"6dc2c9b85df9ab4f5b554305339fd80a90a6cf43","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/head/site_verification.pug","hash":"5168caadc4cf541f5d6676a9c5e8ae47a948f9ad","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/post/post-copyright.pug","hash":"cc1f7ae8a7ce5445277215821092e712ec8cc296","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/post/reward.pug","hash":"594626a18b7efbf771232855dfbce143fb244bc6","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/page/flink.pug","hash":"e2eba0fcb8332cb333b2aff9c76664e40e2e1974","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/page/default-page.pug","hash":"e9459f122af7b733398578f9f0f8ab3c5e12a217","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/page/tags.pug","hash":"8f43fdeaf8cff4a35bab74b48c963786ca015620","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/aplayer.pug","hash":"e939344fd389aeb11864ee697d5fd9b036d8325f","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/effect.pug","hash":"4e37535c63149708ecbedb262336014524ad8723","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/pjax.pug","hash":"4e026840c915327e45331e63e4b7ef287e871204","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/pangu.pug","hash":"f0898509da70388b5c532f19e762756d74080200","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/prismjs.pug","hash":"08979afbfecb4476a5ae8e360947b92624d285b8","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_ad.pug","hash":"a8312b527493dabbadbb1280760168d3bc909a3b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_announcement.pug","hash":"21e019bdc3b1e796bb00976bb29af2d51f873624","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/subtitle.pug","hash":"7b5fea9e1c113cab4c75f9d31d8efebe70d82e7a","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_archives.pug","hash":"73d33b6930e7944187a4b3403daf25d27077a2dd","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_author.pug","hash":"08641633d38903351a7424baf9893d9038ba057d","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_bottom_self.pug","hash":"1dba77d250eeebfb6e293d504352c7e9ea31980b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_categories.pug","hash":"66e383b4ef374951eb87dd1bf4cdb7a667193fb5","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_post_toc.pug","hash":"59d979702fa21d960443824198614d63aaf69662","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_newest_comment.pug","hash":"c02b1779bd0ebca6749f195be096b6ca574bfa29","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_recent_post.pug","hash":"471b20e71a19db1f5115727082e5188200c49383","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_tags.pug","hash":"9755cac8424dc578e9ec07dbcaa429fddbedd392","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_top_self.pug","hash":"7b5ae404a1205546b7de4be42291315cf918f2b3","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/card_webinfo.pug","hash":"12185713f9ca08984fc74e3b69d8cd6828d23da8","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/widget/index.pug","hash":"5e0e9e9b2cd3c256d52423e2278e790aa387a53a","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/highlight.styl","hash":"a2aa5caf338ff5323b6ff0601ebcc09e710d8398","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/theme.styl","hash":"3c178608406c31d768af355ef1d7326da37cc75f","modified":1656900130000},{"_id":"themes/butterfly/source/css/_global/function.styl","hash":"f562648de515abc873609bfe9b9f799c8cf42b72","modified":1656900130000},{"_id":"themes/butterfly/source/css/_global/index.styl","hash":"b9d7d23dc8810542b8c8ffcbfbd3694318debcc6","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/aside.styl","hash":"af6e3357b8f6df18d0775b8352551c0f8ce38e55","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/chat.styl","hash":"f27ad7b5d781c98bcac5c12c2d70b69b830e0374","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/comments.styl","hash":"0abe05309a186682772a94e5e759b63f8028e61a","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/footer.styl","hash":"e931ef81754a7b9d999fa23d134c620e68e75491","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/head.styl","hash":"f3aac52defb3497079a313e8c63ac2f7ee24dfbe","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/post.styl","hash":"9f880a6fa91784a4d3e9ffb0d4607e8a74d4d929","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/pagination.styl","hash":"bd099f7d3adef4b7edd24c0a25a07415b156e587","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/reward.styl","hash":"b5ba2c3339ad406ce611d12d3f8cc84f864fbc03","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/loading.styl","hash":"844858ae87c7278996ce484c6b456db354c48764","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/relatedposts.styl","hash":"6dcf19c0933c8828a439f801b0f4b256447dec07","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/rightside.styl","hash":"1c1c585ba99cb4004956b5e98fc044260b456f99","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/sidebar.styl","hash":"7e9b65dcae7ac54e0183bc841fea0f4bd4d78e5c","modified":1656900130000},{"_id":"themes/butterfly/source/css/_mode/darkmode.styl","hash":"5dabc3a5330cc28f0666d1cd8db0d67f553fd854","modified":1656900130000},{"_id":"themes/butterfly/source/css/_layout/third-party.styl","hash":"e02b52bdd337c0ed3c9d3a507d1011403c38881d","modified":1656900130000},{"_id":"themes/butterfly/source/css/_mode/readmode.styl","hash":"1fed25162d7204480e9bcf476b3246e1717107ca","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/404.styl","hash":"a7223a8fcc4fa7b81e552c9a2554be7df9de312e","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/archives.styl","hash":"d72218cb5a6bfe048ae1c92009bd815a08a53d3a","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/categories.styl","hash":"68bc8cbea25dbb3cdc170f09f9b43ce130547717","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/common.styl","hash":"a714776e3d585369f2285b6bb4e1564539c58d8b","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/flink.styl","hash":"ecc2b2e28c179eb9406fc2c6f00e141078249cdd","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/homepage.styl","hash":"6d2a841c7656fb28b1e15afe1d7dda56c424b7d7","modified":1656900130000},{"_id":"themes/butterfly/source/css/_page/tags.styl","hash":"9e35f91847773b915c74a78b8aa66c7bdb950ad0","modified":1656900130000},{"_id":"themes/butterfly/source/css/_third-party/normalize.min.css","hash":"8549829fb7d3c21cd9e119884962e8c463a4a267","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/gallery.styl","hash":"84c42716e833d2d1dd47195ea996803ffa0e58ec","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/button.styl","hash":"62da1de0d5b8453fcecbfacddb16985265638ba5","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/hexo.styl","hash":"985b183db7b7bfd8f9bdb60494549fb7f850348b","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/hide.styl","hash":"b7cf7753479fcf2fe07287ffdb0e568adbba4c18","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/inlineImg.styl","hash":"5a873d01fabebcf7ddf7a6b1c2e2e5e2714097f4","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/label.styl","hash":"2f83bd145b870d80d4b18b0ac603235229a5694e","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/note.styl","hash":"331c89ecfb79fab68466944a43e9e3d0ff49c646","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/tabs.styl","hash":"ec81ea316c82b83d6aee31e52f248d329559d5d3","modified":1656900130000},{"_id":"themes/butterfly/source/css/_tags/timeline.styl","hash":"07ea7134db7a66c87658116f089fb1a2a6906563","modified":1656900130000},{"_id":"themes/butterfly/source/css/_search/index.styl","hash":"cced94e70b4b90130cfa215582be2adbf883efba","modified":1656900130000},{"_id":"themes/butterfly/source/css/_search/algolia.styl","hash":"d1398399eb7f1cc004fbcefa18f56188cc8fec8c","modified":1656900130000},{"_id":"themes/butterfly/source/css/_search/local-search.styl","hash":"45792c13c7c439d412b7dc597d74d24f3b598406","modified":1656900130000},{"_id":"themes/butterfly/source/js/search/local-search.js","hash":"f72e002d56903a49c36174e77e42f88b8af8bd44","modified":1656900130000},{"_id":"themes/butterfly/source/js/search/algolia.js","hash":"d0d60008ef4ff74298ff062878766f194a2e4a70","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/chatra.pug","hash":"f3f6eaecbcf9352342e259f4a5a3ad7160f31fc9","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/crisp.pug","hash":"b741b5e942481d779a8a1fe94c45154a62a6b748","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/gitter.pug","hash":"794ce3911f17d354b7196deb8c36d191afac63fb","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/daovoice.pug","hash":"e5af55cdb87d1ffd3d8702bc77097159acf95b54","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/index.pug","hash":"bb467bb22f3d0775b33f9eacbfc086ecb7831e78","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/chat/tidio.pug","hash":"cd7ab4a776be93eea96a6f6fd0a547977fbe1ea3","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"f4d21dcbc3b00eed9b1f604e132c4c6811a0a059","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"6a79d114472699e4de1a56a46b9a4f35e8fcd0e4","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"4eebb2d94ca75809ef0cf32d70f13e9bf1e87091","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"716dc463fe4ef5112e7018ed60804125fdfa5cad","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"38b85d216d9377ddbaa2e5867e2f03805227237c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"cd4fc9c5a61608a5dedf645c1295430a1623040f","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqus.pug","hash":"3b551ab7618b36795480015b5cf565288df5b957","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"6e5ccc9ea4346c71ad4cbf1e9f1cb83bb45e6f27","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"8c16214a610ff8087628f32d005a1b0aab3bb910","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"a222477bddba3c646ee9b8560442c2cb204adb11","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"3df2f59c9552a1f2e6f0d50c4ae97e72c5392b59","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/giscus.pug","hash":"319463fc8ff993b798f2293b659b522ad7770cf0","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/livere.pug","hash":"589f8503f264d4fda971c8daf2028f45c4f2867b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/js.pug","hash":"0d845515e457fac530c173905302eb30e045580c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/remark42.pug","hash":"f04263a3bd7efb7f1b250cfee112e82f49805492","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/index.pug","hash":"a348b6b2fb65fe11d256acfac0741074e77fe519","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"ccb5c3f2a821b87986998595743387d7c997c16e","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/valine.pug","hash":"cba55cbbd0962bf84b8956195e686b0e158ed247","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/waline.pug","hash":"e45152e4ebc3fb2462916be93f98d18f0574f2d3","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/comments/utterances.pug","hash":"d48d59ebf8c0142fb3c4592a0d35874f85e6fd4c","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/math/index.pug","hash":"2afa4c21dd19890f47fb568cfb0d90efb676a253","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/math/katex.pug","hash":"f0d3eddd2bed68e5517274b3530bfe0fa5057d8e","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/math/mathjax.pug","hash":"056756e43908519039b8bbd7a90f8c49d561eb52","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/math/mermaid.pug","hash":"297d34d83e7bff8ec3b8bc19bb0f4d901c35fe5a","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/share/add-this.pug","hash":"8b4034e53ca5bf85097f681a6e76a53ce685c205","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/share/addtoany.pug","hash":"1f02a26730e5f36cc2dfec7ff4d5c93a099ed5ba","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/share/index.pug","hash":"4898a09d8e67fb358ffd74b3a1f0014f555dd856","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/share/share-js.pug","hash":"b45fc15c3ae7db3a0fbce0d6da74a72a95ca8a2b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"cd1ce86441dc508e4c3dbf8b829046455ba8a6b4","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"b2ede1f6b41026ebd233ac076a405889a6eec76b","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"6b60941942831cc91e395131ad9797b691632fcb","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"bc207dcb771fc2c2c329f29d01708ff6b18443da","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"91a72e94743befa21a7b1c557fbb3751efb87ab0","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"33368c0b80e4c4e78f3c7ee9bec0fed70ad838ca","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"63ef0b2a75cf26a94c5bcd885f3a1c144451b852","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/search/algolia.pug","hash":"af5d3d87b736598dafcf5871863596592cacdfe1","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/search/index.pug","hash":"ff3727c3ec698ec61a28c55cbc8c8508f0efb0a0","modified":1656900130000},{"_id":"themes/butterfly/layout/includes/third-party/search/local-search.pug","hash":"3b5ef84744a1a8fec5a63554079008040d96f924","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/highlight/diff.styl","hash":"6e77f1ca0cfb0db6b028f5c0238780e66d344f3d","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/highlight/index.styl","hash":"fc702a4614d0562a381907b083f71ba63d301d86","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/prismjs/diff.styl","hash":"1309292f1c8c53d96cd7333507b106bcc24ca8fc","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/prismjs/index.styl","hash":"01ff9e77eb1bd454bec65a6ff5972c8e219bc708","modified":1656900130000},{"_id":"themes/butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"0b8aea62d1550113e1fcc237fae1b03743190208","modified":1656900130000},{"_id":"themes/butterfly/source/img/pics/default_top_img.png","hash":"d57f013d55ac54c1f95eb8bc873c1b7ff0fc5827","modified":1634536214000},{"_id":"themes/butterfly/source/img/pics/index.png","hash":"3ad85e2fa37717d3fef383f53bc9277ada73286f","modified":1646896488000},{"_id":"public/about/index.html","hash":"fb95efd6882dbd07fdecf643dcb0616536bddb77","modified":1658284971199},{"_id":"public/link/index.html","hash":"12728550022019a7e18e1eb3015fccf32eefc884","modified":1658284971199},{"_id":"public/categories/index.html","hash":"7ac78e92d33664032f49722440942badcd90cbb5","modified":1658284971199},{"_id":"public/photo/index.html","hash":"53f66c03fcb603a865a66d43c6c01b7e6b7fdd62","modified":1658284971199},{"_id":"public/tags/index.html","hash":"0ca3c93ad8ea2e1246aa4b438520b926a096f586","modified":1658284971199},{"_id":"public/photo/camera/index.html","hash":"9dfa415792ea172d7c93a43b4fe87f7030a8fde8","modified":1658284971199},{"_id":"public/posts/443336a2.html","hash":"09365e51a005e440a1a44151be036b3173475747","modified":1658284971199},{"_id":"public/posts/24caea6b.html","hash":"ffb86ff0f47470d42b987c8ef2529023eac8b45a","modified":1658284971199},{"_id":"public/archives/index.html","hash":"8840ff3ce9849c7eedbc8e6e284efbc77050d14b","modified":1658284971199},{"_id":"public/archives/2022/index.html","hash":"01694acd54bd3cabca8c002d64db412d2c791070","modified":1658284971199},{"_id":"public/archives/2022/07/index.html","hash":"96ce178ef2f5ff13f334c03ef47359b3e1046e93","modified":1658284971199},{"_id":"public/index.html","hash":"88176620e5190c31473f5afe2caa48f6dbdfd23d","modified":1658284971199},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1658284971199},{"_id":"public/img/favicon.png","hash":"c8171b028fee71af81ff36b84a86f132119cefc7","modified":1658284971199},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1658284971199},{"_id":"public/css/index.css","hash":"80839d5fe23c1e84a76d918318e9c62e50d239f4","modified":1658284971199},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1658284971199},{"_id":"public/js/utils.js","hash":"0b95daada72abb5d64a1e3236049a60120e47cca","modified":1658284971199},{"_id":"public/js/search/local-search.js","hash":"3071a4208fdf89ad7e0031536dd6ffa7bc951e4d","modified":1658284971199},{"_id":"public/js/search/algolia.js","hash":"9feb248552667c53ce1b19bc7a295215f8c77008","modified":1658284971199},{"_id":"public/js/main.js","hash":"73d2624ed465e4cfb1ebb00b2c8a24f5fc29bb21","modified":1658284971199},{"_id":"public/js/tw_cn.js","hash":"00053ce73210274b3679f42607edef1206eebc68","modified":1658284971199},{"_id":"public/img/pics/default_top_img.png","hash":"d57f013d55ac54c1f95eb8bc873c1b7ff0fc5827","modified":1658284971199},{"_id":"public/img/pics/index.png","hash":"3ad85e2fa37717d3fef383f53bc9277ada73286f","modified":1658284971199}],"Category":[],"Data":[],"Page":[{"title":"自我介绍","date":"2022-07-04T03:35:34.000Z","layout":"about","_content":"## 基本情况\n- 97年，在吉林出生和长大\n- 比较中二，想象力太丰富，没办法\n- 希望世界和平\n## 兴趣爱好\n- 摄影\n- 音乐\n- 敲代码","source":"about/index.md","raw":"---\ntitle: 自我介绍\ndate: 2022-07-04 11:35:34\nlayout: about\n---\n## 基本情况\n- 97年，在吉林出生和长大\n- 比较中二，想象力太丰富，没办法\n- 希望世界和平\n## 兴趣爱好\n- 摄影\n- 音乐\n- 敲代码","updated":"2022-07-05T05:45:45.616Z","path":"about/index.html","comments":1,"_id":"cl5t021wh0000nkpd7fewdm25","content":"<h2 id=\"基本情况\"><a href=\"#基本情况\" class=\"headerlink\" title=\"基本情况\"></a>基本情况</h2><ul>\n<li>97年，在吉林出生和长大</li>\n<li>比较中二，想象力太丰富，没办法</li>\n<li>希望世界和平</li>\n</ul>\n<h2 id=\"兴趣爱好\"><a href=\"#兴趣爱好\" class=\"headerlink\" title=\"兴趣爱好\"></a>兴趣爱好</h2><ul>\n<li>摄影</li>\n<li>音乐</li>\n<li>敲代码</li>\n</ul>\n","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":"<h2 id=\"基本情况\"><a href=\"#基本情况\" class=\"headerlink\" title=\"基本情况\"></a>基本情况</h2><ul>\n<li>97年，在吉林出生和长大</li>\n<li>比较中二，想象力太丰富，没办法</li>\n<li>希望世界和平</li>\n</ul>\n<h2 id=\"兴趣爱好\"><a href=\"#兴趣爱好\" class=\"headerlink\" title=\"兴趣爱好\"></a>兴趣爱好</h2><ul>\n<li>摄影</li>\n<li>音乐</li>\n<li>敲代码</li>\n</ul>\n"},{"title":"link","date":"2022-07-04T04:16:29.000Z","type":"link","_content":"","source":"link/index.md","raw":"---\ntitle: link\ndate: 2022-07-04 12:16:29\ntype: link\n---\n","updated":"2022-07-04T04:16:42.000Z","path":"link/index.html","comments":1,"layout":"page","_id":"cl5t021wk0001nkpd2aw1c518","content":"","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":""},{"title":"分类","date":"2022-07-04T03:38:54.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2022-07-04 11:38:54\ntype: categories\n---\n","updated":"2022-07-04T06:16:10.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cl5t021wl0002nkpd7f7g0dy7","content":"","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":""},{"title":"图库","date":"2022-07-04T09:26:16.000Z","type":"photo","_content":"\n<div class=\"gallery-group-main\">\n{% galleryGroup '随手拍' '出门记录生活' '/photo/camera' http://tva1.sinaimg.cn/large/008lIB40ly1h3vzmm5mwsj339l52b4qt.jpg %}\n</div>\n\n\n","source":"photo/index.md","raw":"---\ntitle: 图库\ndate: 2022-07-04 17:26:16\ntype: photo\n---\n\n<div class=\"gallery-group-main\">\n{% galleryGroup '随手拍' '出门记录生活' '/photo/camera' http://tva1.sinaimg.cn/large/008lIB40ly1h3vzmm5mwsj339l52b4qt.jpg %}\n</div>\n\n\n","updated":"2022-07-05T05:30:55.790Z","path":"photo/index.html","comments":1,"layout":"page","_id":"cl5t021wl0003nkpd8wmngxc7","content":"<div class=\"gallery-group-main\">\n\n  <figure class=\"gallery-group\">\n  <img class=\"gallery-group-img no-lightbox\" src='http://tva1.sinaimg.cn/large/008lIB40ly1h3vzmm5mwsj339l52b4qt.jpg' alt=\"Group Image Gallery\">\n  <figcaption>\n  <div class=\"gallery-group-name\">随手拍</div>\n  <p>出门记录生活</p>\n  <a href='/photo/camera'></a>\n  </figcaption>\n  </figure>\n  \n</div>\n\n\n","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":"<div class=\"gallery-group-main\">\n\n  <figure class=\"gallery-group\">\n  <img class=\"gallery-group-img no-lightbox\" src='http://tva1.sinaimg.cn/large/008lIB40ly1h3vzmm5mwsj339l52b4qt.jpg' alt=\"Group Image Gallery\">\n  <figcaption>\n  <div class=\"gallery-group-name\">随手拍</div>\n  <p>出门记录生活</p>\n  <a href='/photo/camera'></a>\n  </figcaption>\n  </figure>\n  \n</div>\n\n\n"},{"title":"标签","date":"2022-07-04T04:14:19.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2022-07-04 12:14:19\ntype: tags\n---\n","updated":"2022-07-04T06:16:34.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cl5t021wm0004nkpd1v3j39ev","content":"","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":""},{"title":"随手拍","date":"2022-07-04T13:54:30.000Z","_content":"\n{% gallery %}\n![IMG_7324.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp5dllj35ci1hcqv5.jpg)\n![IMG_7446.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvf0odj35dc3kwu11.jpg)\n![IMG_7499.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznozbsfj31nf2nue5g.jpg)\n![IMG_7501.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpprt3j32vo3k91ky.jpg)\n![IMG_7513.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqr6vsj33kw5dc4qq.jpg)\n![IMG_7515.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7x6gj33kw5dchdt.jpg)\n![IMG_7546.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpoh5fj32zo4rn4qp.jpg)\n![IMG_7909.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqwa54j33br4znb2a.jpg)\n![IMG_7944.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznr7c4zj33kw5dce82.jpg)\n![IMG_7951.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpj7qrj32ww49nqv5.jpg)\n![IMG_8003_1.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrjj05j35ch32nhdu.jpg)\n![IMG_8004.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7qvtj32wf4bhe81.jpg)\n![IMG_8108.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsaaisj35dc3kwu0z.jpg)\n![IMG_8222.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrfyqbj34yh3kwqv6.jpg)\n![IMG_8297.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznps4nxj32lc33me82.jpg)\n![IMG_8298.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns36bzj33kw5dce84.jpg)\n![IMG_8301.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns6plij32ul4q9x6r.jpg)\n![IMG_8302.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpzvfij32py3431kx.jpg)\n![IMG_8322.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqcwzaj31rc2lmhdt.jpg)\n![IMG_8345.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsz5zdj35dc3kw7wk.jpg)\n![IMG_8347.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznshjlkj34za3i04qr.jpg)\n![IMG_8351.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvt6l3j33ix4eqx6t.jpg)\n![IMG_8359.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwiggyj33hn58gqvb.jpg)\n![IMG_8364.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznt2dr5j32ma41cb2b.jpg)\n![IMG_8459.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp6jm4j31b915zgui.jpg)\n![IMG_8470.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznu5r4nj35dc3kwkjo.jpg)\n![IMG_8489.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntg5o0j33gw4zqnpe.jpg)\n![IMG_8524.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntvbndj33jn5bhu10.jpg)\n![IMG_8531.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznug1wnj33kw5dce84.jpg)\n![IMG_8570.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpmck9j31lt2cvqmp.jpg)\n![IMG_8581.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntmkrzj337y41s7wj.jpg)\n![IMG_8837.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznzht49j35dc3kwhe4.jpg)\n![IMG_8843.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwn48sj339l52b4qt.jpg)\n![IMG_8845.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznyb2f2j34yh3d2qva.jpg)\n![IMG_8852.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqanbfj318n1uy4qp.jpg)\n![IMG_8863.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxqikhj33kw3yvqvb.jpg)\n![IMG_8878.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuw95sj329g3e61kz.jpg)\n![IMG_8900.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznydjzfj35dc3kw1l4.jpg)\n![IMG_8920.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxwlgaj33b54ypb2f.jpg)\n![IMG_8940.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuxhv2j32jk3e9hdw.jpg)\n{% endgallery %}\n\n\n\n","source":"photo/camera/index.md","raw":"---\ntitle: 随手拍\ndate: 2022-07-04 21:54:30\n---\n\n{% gallery %}\n![IMG_7324.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp5dllj35ci1hcqv5.jpg)\n![IMG_7446.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvf0odj35dc3kwu11.jpg)\n![IMG_7499.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznozbsfj31nf2nue5g.jpg)\n![IMG_7501.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpprt3j32vo3k91ky.jpg)\n![IMG_7513.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqr6vsj33kw5dc4qq.jpg)\n![IMG_7515.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7x6gj33kw5dchdt.jpg)\n![IMG_7546.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpoh5fj32zo4rn4qp.jpg)\n![IMG_7909.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqwa54j33br4znb2a.jpg)\n![IMG_7944.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznr7c4zj33kw5dce82.jpg)\n![IMG_7951.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpj7qrj32ww49nqv5.jpg)\n![IMG_8003_1.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrjj05j35ch32nhdu.jpg)\n![IMG_8004.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7qvtj32wf4bhe81.jpg)\n![IMG_8108.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsaaisj35dc3kwu0z.jpg)\n![IMG_8222.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrfyqbj34yh3kwqv6.jpg)\n![IMG_8297.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznps4nxj32lc33me82.jpg)\n![IMG_8298.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns36bzj33kw5dce84.jpg)\n![IMG_8301.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns6plij32ul4q9x6r.jpg)\n![IMG_8302.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpzvfij32py3431kx.jpg)\n![IMG_8322.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqcwzaj31rc2lmhdt.jpg)\n![IMG_8345.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsz5zdj35dc3kw7wk.jpg)\n![IMG_8347.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznshjlkj34za3i04qr.jpg)\n![IMG_8351.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvt6l3j33ix4eqx6t.jpg)\n![IMG_8359.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwiggyj33hn58gqvb.jpg)\n![IMG_8364.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznt2dr5j32ma41cb2b.jpg)\n![IMG_8459.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp6jm4j31b915zgui.jpg)\n![IMG_8470.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznu5r4nj35dc3kwkjo.jpg)\n![IMG_8489.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntg5o0j33gw4zqnpe.jpg)\n![IMG_8524.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntvbndj33jn5bhu10.jpg)\n![IMG_8531.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznug1wnj33kw5dce84.jpg)\n![IMG_8570.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpmck9j31lt2cvqmp.jpg)\n![IMG_8581.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntmkrzj337y41s7wj.jpg)\n![IMG_8837.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznzht49j35dc3kwhe4.jpg)\n![IMG_8843.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwn48sj339l52b4qt.jpg)\n![IMG_8845.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznyb2f2j34yh3d2qva.jpg)\n![IMG_8852.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqanbfj318n1uy4qp.jpg)\n![IMG_8863.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxqikhj33kw3yvqvb.jpg)\n![IMG_8878.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuw95sj329g3e61kz.jpg)\n![IMG_8900.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznydjzfj35dc3kw1l4.jpg)\n![IMG_8920.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxwlgaj33b54ypb2f.jpg)\n![IMG_8940.jpg](http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuxhv2j32jk3e9hdw.jpg)\n{% endgallery %}\n\n\n\n","updated":"2022-07-05T05:34:52.251Z","path":"photo/camera/index.html","comments":1,"layout":"page","_id":"cl5t021wn0005nkpd89d2ciyc","content":"<div class=\"fj-gallery\"><p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp5dllj35ci1hcqv5.jpg\" alt=\"IMG_7324.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvf0odj35dc3kwu11.jpg\" alt=\"IMG_7446.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznozbsfj31nf2nue5g.jpg\" alt=\"IMG_7499.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpprt3j32vo3k91ky.jpg\" alt=\"IMG_7501.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqr6vsj33kw5dc4qq.jpg\" alt=\"IMG_7513.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7x6gj33kw5dchdt.jpg\" alt=\"IMG_7515.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpoh5fj32zo4rn4qp.jpg\" alt=\"IMG_7546.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqwa54j33br4znb2a.jpg\" alt=\"IMG_7909.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznr7c4zj33kw5dce82.jpg\" alt=\"IMG_7944.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpj7qrj32ww49nqv5.jpg\" alt=\"IMG_7951.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrjj05j35ch32nhdu.jpg\" alt=\"IMG_8003_1.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7qvtj32wf4bhe81.jpg\" alt=\"IMG_8004.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsaaisj35dc3kwu0z.jpg\" alt=\"IMG_8108.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrfyqbj34yh3kwqv6.jpg\" alt=\"IMG_8222.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznps4nxj32lc33me82.jpg\" alt=\"IMG_8297.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns36bzj33kw5dce84.jpg\" alt=\"IMG_8298.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns6plij32ul4q9x6r.jpg\" alt=\"IMG_8301.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpzvfij32py3431kx.jpg\" alt=\"IMG_8302.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqcwzaj31rc2lmhdt.jpg\" alt=\"IMG_8322.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsz5zdj35dc3kw7wk.jpg\" alt=\"IMG_8345.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznshjlkj34za3i04qr.jpg\" alt=\"IMG_8347.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvt6l3j33ix4eqx6t.jpg\" alt=\"IMG_8351.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwiggyj33hn58gqvb.jpg\" alt=\"IMG_8359.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznt2dr5j32ma41cb2b.jpg\" alt=\"IMG_8364.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp6jm4j31b915zgui.jpg\" alt=\"IMG_8459.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznu5r4nj35dc3kwkjo.jpg\" alt=\"IMG_8470.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntg5o0j33gw4zqnpe.jpg\" alt=\"IMG_8489.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntvbndj33jn5bhu10.jpg\" alt=\"IMG_8524.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznug1wnj33kw5dce84.jpg\" alt=\"IMG_8531.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpmck9j31lt2cvqmp.jpg\" alt=\"IMG_8570.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntmkrzj337y41s7wj.jpg\" alt=\"IMG_8581.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznzht49j35dc3kwhe4.jpg\" alt=\"IMG_8837.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwn48sj339l52b4qt.jpg\" alt=\"IMG_8843.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznyb2f2j34yh3d2qva.jpg\" alt=\"IMG_8845.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqanbfj318n1uy4qp.jpg\" alt=\"IMG_8852.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxqikhj33kw3yvqvb.jpg\" alt=\"IMG_8863.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuw95sj329g3e61kz.jpg\" alt=\"IMG_8878.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznydjzfj35dc3kw1l4.jpg\" alt=\"IMG_8900.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxwlgaj33b54ypb2f.jpg\" alt=\"IMG_8920.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuxhv2j32jk3e9hdw.jpg\" alt=\"IMG_8940.jpg\"></p>\n          </div>\n\n\n\n","site":{"data":{}},"cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3vvk48c1lj33y8280e87.jpg","excerpt":"","more":"<div class=\"fj-gallery\"><p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp5dllj35ci1hcqv5.jpg\" alt=\"IMG_7324.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvf0odj35dc3kwu11.jpg\" alt=\"IMG_7446.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznozbsfj31nf2nue5g.jpg\" alt=\"IMG_7499.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpprt3j32vo3k91ky.jpg\" alt=\"IMG_7501.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqr6vsj33kw5dc4qq.jpg\" alt=\"IMG_7513.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7x6gj33kw5dchdt.jpg\" alt=\"IMG_7515.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpoh5fj32zo4rn4qp.jpg\" alt=\"IMG_7546.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqwa54j33br4znb2a.jpg\" alt=\"IMG_7909.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznr7c4zj33kw5dce82.jpg\" alt=\"IMG_7944.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpj7qrj32ww49nqv5.jpg\" alt=\"IMG_7951.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrjj05j35ch32nhdu.jpg\" alt=\"IMG_8003_1.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznq7qvtj32wf4bhe81.jpg\" alt=\"IMG_8004.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsaaisj35dc3kwu0z.jpg\" alt=\"IMG_8108.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznrfyqbj34yh3kwqv6.jpg\" alt=\"IMG_8222.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznps4nxj32lc33me82.jpg\" alt=\"IMG_8297.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns36bzj33kw5dce84.jpg\" alt=\"IMG_8298.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzns6plij32ul4q9x6r.jpg\" alt=\"IMG_8301.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpzvfij32py3431kx.jpg\" alt=\"IMG_8302.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqcwzaj31rc2lmhdt.jpg\" alt=\"IMG_8322.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznsz5zdj35dc3kw7wk.jpg\" alt=\"IMG_8345.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznshjlkj34za3i04qr.jpg\" alt=\"IMG_8347.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznvt6l3j33ix4eqx6t.jpg\" alt=\"IMG_8351.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwiggyj33hn58gqvb.jpg\" alt=\"IMG_8359.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznt2dr5j32ma41cb2b.jpg\" alt=\"IMG_8364.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznp6jm4j31b915zgui.jpg\" alt=\"IMG_8459.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznu5r4nj35dc3kwkjo.jpg\" alt=\"IMG_8470.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntg5o0j33gw4zqnpe.jpg\" alt=\"IMG_8489.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntvbndj33jn5bhu10.jpg\" alt=\"IMG_8524.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznug1wnj33kw5dce84.jpg\" alt=\"IMG_8531.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznpmck9j31lt2cvqmp.jpg\" alt=\"IMG_8570.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vzntmkrzj337y41s7wj.jpg\" alt=\"IMG_8581.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznzht49j35dc3kwhe4.jpg\" alt=\"IMG_8837.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznwn48sj339l52b4qt.jpg\" alt=\"IMG_8843.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznyb2f2j34yh3d2qva.jpg\" alt=\"IMG_8845.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznqanbfj318n1uy4qp.jpg\" alt=\"IMG_8852.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxqikhj33kw3yvqvb.jpg\" alt=\"IMG_8863.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuw95sj329g3e61kz.jpg\" alt=\"IMG_8878.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznydjzfj35dc3kw1l4.jpg\" alt=\"IMG_8900.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznxwlgaj33b54ypb2f.jpg\" alt=\"IMG_8920.jpg\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3vznuxhv2j32jk3e9hdw.jpg\" alt=\"IMG_8940.jpg\"></p>\n          </div>\n\n\n\n"}],"Post":[{"title":"Hexo常用命令","top_img":"http://tva1.sinaimg.cn/large/008lIB40ly1h3zth54jhuj32yo1o0nph.jpg","cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3zth54jhuj32yo1o0nph.jpg","abbrlink":"24caea6b","date":"2022-07-08T08:13:28.000Z","_content":"\n# Hexo常用命令\n\n### hexo init\n\n`hexo init` 用于初始化hexo， 新建文件夹做为网站的根目录\n\n```shell\nhexo init [folder]\n```\n\n- `floder` 为可选参数，用于指定初始化目录的路径，若无指定则默认为当前目录\n\n### hexo new\n\n`hexo new` 用于新建文章，同时也可以简写为 `hexo n`\n\n```shell\nhexo new [layout] <title>\n```\n\n- `alyout`  **可选参数**， 用于指定文章类型，若无指定则默认由配置文件中的default_layout选择决定（默认为post）\n- `title` **必填参数**，用于指定文章标题，如果参数值中含有空格，则需要使用双引号包围\n\n### hexo generate\n\n`hexo generate` 用于生成静态文件，一般可以简写为 `hexo g`\n\n```shell\nhexo generate\n```\n\n### hexo server\n\n`hexo server` 用于启动本地服务器，一般可以简写为 `hexo s`\n\n```shell\nhexo server\n```\n\n- `-port` 选填，指定服务器端口，默认为 4000，可简写为 `-p`\n- `-ip` 选填， 指定服务器IP地址，默认为 0.0.0.0， 可简写为`-i`\n- `-static`  选填，静态模式，仅提供public文件夹中的文件并禁用文件监视\n\n{% note warning no-icon %} 运行hexo依赖hexo-server插件 {% endnote %}\n\n```shell\nnpm install hexo-server --save\n```\n\n### hexo deploy\n\n`hexo deploy` 命令用于部署网站，一般可以简写为`hexo d`\n\n```shell\nhexo deploy\n```\n\n{% note warning no-icon %} 部署前需要填写_config.yml配置文件中的deploy {% endnote %}\n\n### hexo clean\n\n`hexo clean`用于清理缓存文件\n\n```shell\nhexo clean\n```\n\n# 总结\n\n命令之间可以使用`&&`链接，进行连续执行\n\n#### 例：\n\n1. 清理缓存 -> 2. 生成静态文件 -> 3. 开启本地服务\n\n```shell\nhexo clean && hexo g && hexo s\n```\n\n2. 清理缓存 -> 2. 生成静态文件 -> 3. 文件部署\n\n```shell\nhexo clean && hexo g && hexo d\n```\n\n","source":"_posts/Hexo常用命令.md","raw":"---\ntitle: Hexo常用命令\ntop_img: http://tva1.sinaimg.cn/large/008lIB40ly1h3zth54jhuj32yo1o0nph.jpg\ncover: http://tva1.sinaimg.cn/large/008lIB40ly1h3zth54jhuj32yo1o0nph.jpg\nabbrlink: 24caea6b\ndate: 2022-07-08 16:13:28\n---\n\n# Hexo常用命令\n\n### hexo init\n\n`hexo init` 用于初始化hexo， 新建文件夹做为网站的根目录\n\n```shell\nhexo init [folder]\n```\n\n- `floder` 为可选参数，用于指定初始化目录的路径，若无指定则默认为当前目录\n\n### hexo new\n\n`hexo new` 用于新建文章，同时也可以简写为 `hexo n`\n\n```shell\nhexo new [layout] <title>\n```\n\n- `alyout`  **可选参数**， 用于指定文章类型，若无指定则默认由配置文件中的default_layout选择决定（默认为post）\n- `title` **必填参数**，用于指定文章标题，如果参数值中含有空格，则需要使用双引号包围\n\n### hexo generate\n\n`hexo generate` 用于生成静态文件，一般可以简写为 `hexo g`\n\n```shell\nhexo generate\n```\n\n### hexo server\n\n`hexo server` 用于启动本地服务器，一般可以简写为 `hexo s`\n\n```shell\nhexo server\n```\n\n- `-port` 选填，指定服务器端口，默认为 4000，可简写为 `-p`\n- `-ip` 选填， 指定服务器IP地址，默认为 0.0.0.0， 可简写为`-i`\n- `-static`  选填，静态模式，仅提供public文件夹中的文件并禁用文件监视\n\n{% note warning no-icon %} 运行hexo依赖hexo-server插件 {% endnote %}\n\n```shell\nnpm install hexo-server --save\n```\n\n### hexo deploy\n\n`hexo deploy` 命令用于部署网站，一般可以简写为`hexo d`\n\n```shell\nhexo deploy\n```\n\n{% note warning no-icon %} 部署前需要填写_config.yml配置文件中的deploy {% endnote %}\n\n### hexo clean\n\n`hexo clean`用于清理缓存文件\n\n```shell\nhexo clean\n```\n\n# 总结\n\n命令之间可以使用`&&`链接，进行连续执行\n\n#### 例：\n\n1. 清理缓存 -> 2. 生成静态文件 -> 3. 开启本地服务\n\n```shell\nhexo clean && hexo g && hexo s\n```\n\n2. 清理缓存 -> 2. 生成静态文件 -> 3. 文件部署\n\n```shell\nhexo clean && hexo g && hexo d\n```\n\n","slug":"Hexo常用命令","published":1,"updated":"2022-07-08T14:04:47.124Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl5t021x50006nkpd1t4689br","content":"<h1 id=\"Hexo常用命令\"><a href=\"#Hexo常用命令\" class=\"headerlink\" title=\"Hexo常用命令\"></a>Hexo常用命令</h1><h3 id=\"hexo-init\"><a href=\"#hexo-init\" class=\"headerlink\" title=\"hexo init\"></a>hexo init</h3><p><code>hexo init</code> 用于初始化hexo， 新建文件夹做为网站的根目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init [folder]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>floder</code> 为可选参数，用于指定初始化目录的路径，若无指定则默认为当前目录</li>\n</ul>\n<h3 id=\"hexo-new\"><a href=\"#hexo-new\" class=\"headerlink\" title=\"hexo new\"></a>hexo new</h3><p><code>hexo new</code> 用于新建文章，同时也可以简写为 <code>hexo n</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>alyout</code>  <strong>可选参数</strong>， 用于指定文章类型，若无指定则默认由配置文件中的default_layout选择决定（默认为post）</li>\n<li><code>title</code> <strong>必填参数</strong>，用于指定文章标题，如果参数值中含有空格，则需要使用双引号包围</li>\n</ul>\n<h3 id=\"hexo-generate\"><a href=\"#hexo-generate\" class=\"headerlink\" title=\"hexo generate\"></a>hexo generate</h3><p><code>hexo generate</code> 用于生成静态文件，一般可以简写为 <code>hexo g</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"hexo-server\"><a href=\"#hexo-server\" class=\"headerlink\" title=\"hexo server\"></a>hexo server</h3><p><code>hexo server</code> 用于启动本地服务器，一般可以简写为 <code>hexo s</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo server</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>-port</code> 选填，指定服务器端口，默认为 4000，可简写为 <code>-p</code></li>\n<li><code>-ip</code> 选填， 指定服务器IP地址，默认为 0.0.0.0， 可简写为<code>-i</code></li>\n<li><code>-static</code>  选填，静态模式，仅提供public文件夹中的文件并禁用文件监视</li>\n</ul>\n<div class=\"note warning no-icon flat\"><p>运行hexo依赖hexo-server插件 </p>\n</div>\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-server --save</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"hexo-deploy\"><a href=\"#hexo-deploy\" class=\"headerlink\" title=\"hexo deploy\"></a>hexo deploy</h3><p><code>hexo deploy</code> 命令用于部署网站，一般可以简写为<code>hexo d</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>\n\n<div class=\"note warning no-icon flat\"><p>部署前需要填写_config.yml配置文件中的deploy </p>\n</div>\n\n<h3 id=\"hexo-clean\"><a href=\"#hexo-clean\" class=\"headerlink\" title=\"hexo clean\"></a>hexo clean</h3><p><code>hexo clean</code>用于清理缓存文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>命令之间可以使用<code>&amp;&amp;</code>链接，进行连续执行</p>\n<h4 id=\"例：\"><a href=\"#例：\" class=\"headerlink\" title=\"例：\"></a>例：</h4><ol>\n<li>清理缓存 -&gt; 2. 生成静态文件 -&gt; 3. 开启本地服务</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>清理缓存 -&gt; 2. 生成静态文件 -&gt; 3. 文件部署</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Hexo常用命令\"><a href=\"#Hexo常用命令\" class=\"headerlink\" title=\"Hexo常用命令\"></a>Hexo常用命令</h1><h3 id=\"hexo-init\"><a href=\"#hexo-init\" class=\"headerlink\" title=\"hexo init\"></a>hexo init</h3><p><code>hexo init</code> 用于初始化hexo， 新建文件夹做为网站的根目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init [folder]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>floder</code> 为可选参数，用于指定初始化目录的路径，若无指定则默认为当前目录</li>\n</ul>\n<h3 id=\"hexo-new\"><a href=\"#hexo-new\" class=\"headerlink\" title=\"hexo new\"></a>hexo new</h3><p><code>hexo new</code> 用于新建文章，同时也可以简写为 <code>hexo n</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>alyout</code>  <strong>可选参数</strong>， 用于指定文章类型，若无指定则默认由配置文件中的default_layout选择决定（默认为post）</li>\n<li><code>title</code> <strong>必填参数</strong>，用于指定文章标题，如果参数值中含有空格，则需要使用双引号包围</li>\n</ul>\n<h3 id=\"hexo-generate\"><a href=\"#hexo-generate\" class=\"headerlink\" title=\"hexo generate\"></a>hexo generate</h3><p><code>hexo generate</code> 用于生成静态文件，一般可以简写为 <code>hexo g</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"hexo-server\"><a href=\"#hexo-server\" class=\"headerlink\" title=\"hexo server\"></a>hexo server</h3><p><code>hexo server</code> 用于启动本地服务器，一般可以简写为 <code>hexo s</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo server</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>-port</code> 选填，指定服务器端口，默认为 4000，可简写为 <code>-p</code></li>\n<li><code>-ip</code> 选填， 指定服务器IP地址，默认为 0.0.0.0， 可简写为<code>-i</code></li>\n<li><code>-static</code>  选填，静态模式，仅提供public文件夹中的文件并禁用文件监视</li>\n</ul>\n<div class=\"note warning no-icon flat\"><p>运行hexo依赖hexo-server插件 </p>\n</div>\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-server --save</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"hexo-deploy\"><a href=\"#hexo-deploy\" class=\"headerlink\" title=\"hexo deploy\"></a>hexo deploy</h3><p><code>hexo deploy</code> 命令用于部署网站，一般可以简写为<code>hexo d</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>\n\n<div class=\"note warning no-icon flat\"><p>部署前需要填写_config.yml配置文件中的deploy </p>\n</div>\n\n<h3 id=\"hexo-clean\"><a href=\"#hexo-clean\" class=\"headerlink\" title=\"hexo clean\"></a>hexo clean</h3><p><code>hexo clean</code>用于清理缓存文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>命令之间可以使用<code>&amp;&amp;</code>链接，进行连续执行</p>\n<h4 id=\"例：\"><a href=\"#例：\" class=\"headerlink\" title=\"例：\"></a>例：</h4><ol>\n<li>清理缓存 -&gt; 2. 生成静态文件 -&gt; 3. 开启本地服务</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>清理缓存 -&gt; 2. 生成静态文件 -&gt; 3. 文件部署</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>\n\n"},{"title":"深度学习-相似度点选","abbrlink":"443336a2","date":"2022-07-08T13:17:37.000Z","top_img":"http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg","cover":"http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg","_content":"\n## 分析\n\n根据提示依次点击对应文字或图形完成验证。\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h3zumbwf57j30o60et440.jpg)\n\n这种验证码由于按照提示顺序进行点击，故不需识别出准确的文字。本文以WPH为例子，只记录使用小图切割+YOLOV5目标识别+相似度来返回指定坐标\n\n`url: aHR0cHM6Ly9wYXNzcG9ydC52aXAuY29tL2xvZ2luP3NyYz1odHRwcyUzQSUyRiUyRnd3dy52aXAuY29tJTJG`\n\n## 准备工作\n\n直接上selenium简单粗暴，从网站上下载一些图片为后续工作做准备\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hicq5f7j30n50620w0.jpg)\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hizuusqj30nk056tb1.jpg)\n\n## YOLO目标识别\n\n### YOLO简介\n下载yoloV5（[点击进入github](https://github.com/ultralytics/yolov5)），或使用`Git Bash`在指定文件夹目录下输入下面命令行获取：\n```bash\ngit clone https://github.com/ultralytics/yolov5.git\n```\n下载好之后进入yolov5根目录，运行`pip install -r requirements.txt`安装环境\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h43ypy4kryj305h0ag0v5.jpg)\n> 项目文件结构简单说明：\n> `data` 主要放置相关训练数据的配置文件（读取、解析等）\n> `models` 放置各模型的参数配置文件\n> `weights` 放置预训练模型的权重文件\n> `inference` 放置预测/推理阶段的测试图片\n> `runs` 放置训练过程中保留下来的一些数据（运行后自动创建）\n\n### 图片标注\n下载labelimg可视化图形标定工具（[点击下载](https://tzutalin.github.io/labelImg/)），Faster R-CNN，YOLO，SSD等目标检测网络所需要的数据集，均需要借此工具标定图像中的目标。生成的 XML 文件是遵循 PASCAL VOC 的格式的。软件打开界面如下：\n\n{% note info %} labelimg一定要放到全英文路径下，否则会报错 {% endnote %}\n软件打开界面如下：\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i6f6385j30vr0madol.jpg)\n软件功能介绍：\n> 按键功能介绍\n> 在labelImg窗口的左边功能键介绍:\n> “Open”是打开单个图像，\n> “Open Dir” 打开文件夹，\n> \"Change Save Dir\" xml标注文件保存的路径，\n> “Next Image” 切换到下一张图像，\n> “Prev Image”切换到上一张图像，\n> “Verify Image”校验图像，\n> “Save”保存图像，\n> “Create RectBox”画标注框一个，\n> “Duplicate RectBox”重复标注框，\n> “Delete RectBox”删除标注框，\n> “Zoom In” 放大图像，\n> “Zoom Out” 缩小图像，\n> “Fit Window”图像适用窗口，\n> “Fit Width”图像适应宽度。\n> 一组快捷键：\n> ![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i8py03vj30jd0ddwhx.jpg)\n> 过程\n> 一般操作的顺序：单张图片的：\n> “open file ” -----\"create rectbox \" -----\"输入类别名称 \"-----“change save dir ”-----\"Save\"\n> 如果多张图片可以open dir先打开一个文件夹，然后change save dir 选择需要存储的文件夹，其余操作如上，保存后即可Next Image跳下一张。\n> 最后在保存文件的路径下生成.xml文件，.xml文件的名字是和标注照片的名字一样，如果要修改已经标注过的图像，.xml中的信息也会随之改变。\n> 得到的.xml 和PASCAL VOC所用格式相同。\n\n下图则是标记好的实例数据，这里我将所有的文字都标记成了同一个label\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40zkqhjsvj30fx0ui7c7.jpg)\n\n\n### 数据集制作\n#### 图片数据集\n- 将所有的图片放到`JPEGImages`文件夹下，在根目录下创建make_txt.py文件，代码如下，运行代码后`ImageSets`中生成数据集分类txt文件\n```python\nimport os\nimport random\ntrainval_percent = 0.1\ntrain_percent = 0.9\nxmlfilepath = 'data/Annotations'\ntxtsavepath = 'data/ImageSets'\ntotal_xml = os.listdir(xmlfilepath)\nnum = len(total_xml)\nlist = range(num)\ntv = int(num * trainval_percent)\ntr = int(tv * train_percent)\ntrainval = random.sample(list, tv)\ntrain = random.sample(trainval, tr)\nftrainval = open('data/ImageSets/trainval.txt', 'w')\nftest = open('data/ImageSets/test.txt', 'w')\nftrain = open('data/ImageSets/train.txt', 'w')\nfval = open('data/ImageSets/val.txt', 'w')\nfor i in list:\n    name = total_xml[i][:-4] + '\\n'\n    if i in trainval:\n        ftrainval.write(name)\n        if i in train:\n            ftest.write(name)\n        else:\n            fval.write(name)\n    else:\n        ftrain.write(name)\nftrainval.close()\nftrain.close()\nfval.close()\nftest.close()\n```\n{% note info no-icon %}\n运行完成后会在ImageSets中看到做好的数据集分类\n{% endnote %}\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h443bznu3lj303f02rglu.jpg)\n#### 标记数据集\n- 将所有个pascal-voc格式的xml文件放入到Annotations文件夹下，根目录下创建 voc_label.py 文件，代码如下。需要注意的是，sets中改为你的sets的名字（make_txt生成的） classes修改为你需要检测的类别，在本案例中，我们只需要检测一种类别\n```python\nimport xml.etree.ElementTree as ET\nimport os\nfrom os import getcwd\n\nsets = ['train', 'test', 'val']\nclasses = ['1']\n\n\ndef convert(size, box):\n    dw = 1. / size[0]\n    dh = 1. / size[1]\n    x = (box[0] + box[1]) / 2.0\n    y = (box[2] + box[3]) / 2.0\n    w = box[1] - box[0]\n    h = box[3] - box[2]\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return x, y, w, h\n\n\ndef convert_annotation(image_id):\n    in_file = open('data/Annotations/%s.xml' % image_id)\n    out_file = open('data/labels/%s.txt' % image_id, 'w')\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find('size')\n    w = int(size.find('width').text)\n    h = int(size.find('height').text)\n    for obj in root.iter('object'):\n        difficult = obj.find('difficult').text\n        cls = obj.find('name').text\n        if cls not in classes or int(difficult) == 1:\n            continue\n        cls_id = classes.index(cls)\n        xmlbox = obj.find('bndbox')\n        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n             float(xmlbox.find('ymax').text))\n        bb = convert((w, h), b)\n        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n\n\nwd = getcwd()\nprint(wd)\nfor image_set in sets:\n    if not os.path.exists('data/labels/'):\n        os.makedirs('data/labels/')\n    image_ids = open('data/ImageSets/%s.txt' % image_set).read().strip().split()\n    list_file = open('data/%s.txt' % image_set, 'w')\n    for image_id in image_ids:\n        list_file.write('data/images/%s.png\\n' % image_id)\n        convert_annotation(image_id)\n    list_file.close()\n```\n{% note info no-icon %}\n运行完成后会在data/label中看到做好的标签文件，并且在data文件下出现了train、val、test的txt文件，保存了图片的路径\n{% endnote %}\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4459bvkr4j30qa04vwkk.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h445a78m6kj302q01rmx5.jpg)\n\n至此我们训练前期的准备工作差不多已经做完了\n### 调整参数\n接下来需要简单的修改一下配置，就可以开始我们的训练了\n1. 进入到data文件下，修改coco.yaml文件\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4493scqutj30nx030jun.jpg)\n- `path` 为train.txt 、 val.txt与test.txt所在的路径，绝对路径与相对路径均可\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4495wnn78j306o01sgly.jpg)\n- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改\n- `names` 把所有标记的种类写入进来\n\n2. 进入models文件夹，修改五个模型中任意即可\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h44993v12ij303702qt91.jpg)\n- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改\n\n3. 进入根目录，修改train.py文件\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46awu34mbj30qo05ngtk.jpg)\n`weights`，`yaml`，`data`按照自己所需文件的路径修改即可 epochs迭代次数自己决定，我这里仅用100次进行测试 batch-size过高可能会影响电脑运行速度，还是要根据自己电脑硬件条件决定增加还是减少 修改完成，运行即可！\n   \n\n### 开始训练\n激动人心的时刻即将到来，在yolov5根目录运行`python  train.py`，即可看到训练已经开始了。如果运行异常，则需要反查自己的环境以及配置的路径是否有误。\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46e9u1ervj30u10c6nc1.jpg)\n\n训练程序正常后可以在根目录运行`tensorboard --logdir runs/train`， 然后在浏览器打开`localhost:6006`观察，效果如下\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46egunvn4j30sj0jvdln.jpg)\n\n### 结束训练\n漫长的等待之后，训练结束\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gw2qzdjj30uh07ik0c.jpg)\n可以看到文件夹里躺着训练结果\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gyatsmpj30s208o0y2.jpg)\nweights里面静静躺着训练出的模型文件\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gzrer13j30h501gq39.jpg)\n\n### 验证结果\n训练结束之后就需要测试我们的模型识别成功率如何，使用根目录下`detect.py`文件来测试，但是还需要指定一些内容，有以下几种方式可以实现\n1. 命令行运行\n```bash\npython detect.py --weights runs/train/exp17/weights/best.pt --source data/Samples/ --device cpu\n```\n> `weights` 为最终训练出来的模型\n> `source` 为测试图片存放位置\n> `device` 为加载模型使用的设备\n2. pycharm中指定参数\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jjh1ykgj30pk0epq7m.jpg)\n> 在pycharm的配置中添加参数，直接运行即可\n\n运行结束后会在`yolov5\\runs\\detect`路径中查看识别结果，可以看到识别准确率还是非常高的，至此我们的目标识别这一部分就做完了\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jx9pmlpj30i903ywgj.jpg)\n\n## 小图切割\n当大图的训练结束之后，则需要处理小图了。在大量观察后发现小图均有一定的规律，提示要点击的文字均处在同一位置上，那么我们就可以通过最简单的方法：直接指定像素进行图片切割来快速提取出来需要点击的文字\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46kmrmjjxj30q409q462.jpg)\n```python\nfrom PIL import Image\nimport os\n\n\ndef splitimage(img):\n    # 小图切割\n    coordinates_list = [149, 192, 235]  # 需要切割的像素位置\n    result = list()\n    for index, x in enumerate(coordinates_list):\n        box = (x, 1, x + 26, 28)\n        small_pic = img.crop(box)\n        result.append(small_pic)\n    return result\n\n\nbig_img_dir = r'.\\yolov5\\data\\images'  # 大图所在路径\nyolo_img_list = os.listdir(big_img_dir)\n\nfor img_name in yolo_img_list:\n    print(img_name)\n\n    img_name = img_name.split('.')[0]\n    cut_img_list = splitimage(Image.open(fr'small_img/{img_name}.png'))  # 与大图对应的小图进行切割\n    if not os.path.exists(f'./small_img_cut/{img_name}'):\n        os.makedirs(f'./small_img_cut/{img_name}')\n\n    for index, cut_img in enumerate(cut_img_list):\n        cut_img.save(f'./small_img_cut/{img_name}/{index}.png')  # 切割后图片保存\n```\n运行结束后可以看到每个小图已经切割成功，并单独存入单独的文件夹内\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eihrabnj30860c778e.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eisgj0lj309603rt8r.jpg)\n那么这一步小图也处理完成，仅仅剩下最后一步就可以完成识别了\n\n## 孪生网络相似度训练\n### 孪生网络简介\n这里就不过多介绍了，可以直接去大佬github中详细学习[点击进入](https://github.com/bubbliiiing/Siamese-keras)\n### 数据集制作\n这里我对yolov5中的detect.py进行了小小的改动，将识别出来的大图放入到之前切割好的小图中，方便我们后续操作\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47r3g7i0oj30po04rdhy.jpg)\n代码如下：\n```python\nfrom pathlib import Path\nimport cv2\nimport torch\nimport numpy as np\nfrom utils.augmentations import letterbox\nfrom models.common import DetectMultiBackend\nfrom utils.general import check_img_size, non_max_suppression, scale_coords\nfrom utils.plots import save_one_box\n\n\nclass Detect:\n    def __init__(self,\n                 weights='weights/best.pt',  # model.pt path(s)\n                 source='data/Samples',  # file/dir/URL/glob, 0 for webcam\n                 data='data/coco128.yaml',  # dataset.yaml path\n                 imgsz=(640, 640),  # inference size (height, width)\n                 project='runs/detect',  # save results to project/name\n                 ):\n        self.source = str(source)\n        self.weights = weights\n        self.data = data\n        self.imgsz = imgsz\n\n        self.model = None\n\n        self.save_dir = Path(project)  # increment run\n        self.save_dir.mkdir(parents=True, exist_ok=True)  # make dir\n        self.load_model()\n\n    def load_model(self):\n        self.model = DetectMultiBackend(self.weights, data=self.data)\n        stride, names, pt = self.model.stride, self.model.names, self.model.pt\n        imgsz = check_img_size(self.imgsz, s=stride)  # check image size\n        bs = 1  # batch_size\n        self.model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n\n    def identify(self, pic_path):\n        im0s = cv2.imread(pic_path)\n        img = letterbox(im0s)[0]\n        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n        im = np.ascontiguousarray(img)\n        im = torch.from_numpy(im).to().float()\n        im /= 255  # 0 - 255 to 0.0 - 1.0\n        if len(im.shape) == 3:\n            im = im[None]  # expand for batch dim\n\n        pred = self.model(im)\n        pred = non_max_suppression(pred)\n\n        for i, det in enumerate(pred):  # per image\n            im0 = im0s.copy()\n\n            p = Path(pic_path)  # to Path\n            imc = im0.copy()\n            if len(det):\n                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n                for *xyxy, conf, cls in reversed(det):\n                    save_file_path = Path(r'E:\\blog\\deep_learn\\small_img_cut') / p.stem / f'{p.stem}.jpg'\n                    save_one_box(xyxy, imc, file=save_file_path, BGR=True)\n                    # print([i.cpu().detach().numpy().tolist() for i in xyxy])\n\n\nif __name__ == '__main__':\n    import os\n    test = Detect()\n\n    pic_list = os.listdir(r'E:\\blog\\deep_learn\\yolov5\\data\\images')\n    for pic in pic_list:\n        test.identify(fr'E:\\blog\\deep_learn\\big_img\\{pic}')\n```\n接下来需要将相同的文字都放入到一个单独的文件夹内，为了能够快速处理，可以使用一下代码实现。\n```python\nimport time\nimport tkinter\nfrom pathlib import Path\nimport os\nimport cv2\nimport hashlib\nimport random\nimport numpy as np\n\nFILE = Path(__file__).resolve()\nROOT = FILE.parents[0]\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))\nroot = tkinter.Tk()\nroot.title(\"Preview\")\n\nnum = 1\n\n\ndef image_Splicing(data):\n    for big_pic in data['big_pic_path']:\n        for small_pic in data['small_pic_path']:\n\n            cv2.namedWindow('Face', 0)  # 创建一个名为“Face”的窗口用于显示图像\n            cv2.moveWindow('Face', 100, 50)  # 移动窗口到适当位置\n            cv2.resizeWindow('Face', 350, 175)\n            img1 = cv2.imread(str(big_pic))\n            img2 = cv2.imread(str(small_pic))\n\n            img1 = cv2.resize(img1, (640, 640))\n            img2 = cv2.resize(img2, (640, 640))\n            new_img = np.hstack([img1, img2])\n            cv2.imshow('Face', new_img)  # 显示图像\n            cv2.waitKey(100)  # 设置显示时间，1000ms\n            judge = input('是否相同：')\n            if judge:\n                print(big_pic, small_pic)\n                tag_pic(big_pic, small_pic)\n                data['big_pic_path'].remove(big_pic)\n                data['small_pic_path'].remove(small_pic)\n                return image_Splicing(data)\n\n            cv2.destroyWindow('Face')\n\n\ndef get_pic_list():\n    pic_id_list = os.listdir(Path(ROOT / 'small_img_cut'))\n    for pic_id in pic_id_list:\n        pic_list = os.listdir(Path(ROOT / 'small_img_cut' / pic_id))\n        data = {'pic_id': pic_id, 'small_pic_path': [], 'big_pic_path': []}\n        for pic in pic_list:\n            pic_path = Path(ROOT / 'small_img_cut' / pic_id / pic)\n            if len(pic_path.stem) < 5:\n                data['small_pic_path'].append(pic_path)\n            else:\n                data['big_pic_path'].append(pic_path)\n        image_Splicing(data)\n\n\ndef hash():\n    time12 = int(time.time() * 1000)\n    rand04 = random.randint(1000, 9999)\n    return md5(str(time12) + str(rand04))\n\n\ndef md5(*arg):\n    hl = hashlib.md5()\n    line = ''.join(list(map(lambda x: str(x), arg)))\n    hl.update(line.encode(encoding='utf-8'))\n    return hl.hexdigest()\n\n\ndef tag_pic(big_pic, small_pic):\n    global num\n    path = f'./Siamese-pytorch/datasets/images_background/pic{num}'\n    num += 1\n    if not os.path.exists(path):\n        os.mkdir(path)\n\n    big_file = open(big_pic, \"rb\")\n    big_data = big_file.read()\n    big_file.close()\n\n    for i in range(5):\n        new_file = open(f\"{path}/{hash()}.jpg\", \"wb\")\n        new_file.write(big_data)\n        new_file.close()\n\n    small_file = open(small_pic, \"rb\")\n    small_data = small_file.read()\n    small_file.close()\n\n    for i in range(5):\n        new_file = open(f\"{path}/{hash()}.jpg\", \"wb\")\n        new_file.write(small_data)\n        new_file.close()\n\n\nif __name__ == '__main__':\n    get_pic_list()\n```\n运行以上代码后可以看到会显示以下图片\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce2aod6yj309s05raav.jpg)\n并且在控制台会有以下内容\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce33kqxzj302t01d0sl.jpg)\n接下来只需要动动自己那发财的小手，如果相同则输入`1`后回车，如果不相同则直接回车。 就可以看到datasets中开始保存相同的文字图片了\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6854b5yj30ry08in12.jpg)\n接下来的开始训练，结束训练以及验证结果均可以查看大佬的github进行操作，这里直接说结果，可以看到识别准确率还是很高的\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6p2ylhnj30gk0aa41t.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6pcl6d1j30gv09f41s.jpg)\n## 结尾\n最后只需要将两个识别方法进行拼接，并删除掉不相关代码，即可实现识别对应问题或图形，也可通过flask来实现接口调用","source":"_posts/深度学习-相似度点选.md","raw":"---\ntitle: 深度学习-相似度点选\nabbrlink: 443336a2\ndate: 2022-07-08 21:17:37\ntags:\ntop_img: http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg\ncover: http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg\n---\n\n## 分析\n\n根据提示依次点击对应文字或图形完成验证。\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h3zumbwf57j30o60et440.jpg)\n\n这种验证码由于按照提示顺序进行点击，故不需识别出准确的文字。本文以WPH为例子，只记录使用小图切割+YOLOV5目标识别+相似度来返回指定坐标\n\n`url: aHR0cHM6Ly9wYXNzcG9ydC52aXAuY29tL2xvZ2luP3NyYz1odHRwcyUzQSUyRiUyRnd3dy52aXAuY29tJTJG`\n\n## 准备工作\n\n直接上selenium简单粗暴，从网站上下载一些图片为后续工作做准备\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hicq5f7j30n50620w0.jpg)\n\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hizuusqj30nk056tb1.jpg)\n\n## YOLO目标识别\n\n### YOLO简介\n下载yoloV5（[点击进入github](https://github.com/ultralytics/yolov5)），或使用`Git Bash`在指定文件夹目录下输入下面命令行获取：\n```bash\ngit clone https://github.com/ultralytics/yolov5.git\n```\n下载好之后进入yolov5根目录，运行`pip install -r requirements.txt`安装环境\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h43ypy4kryj305h0ag0v5.jpg)\n> 项目文件结构简单说明：\n> `data` 主要放置相关训练数据的配置文件（读取、解析等）\n> `models` 放置各模型的参数配置文件\n> `weights` 放置预训练模型的权重文件\n> `inference` 放置预测/推理阶段的测试图片\n> `runs` 放置训练过程中保留下来的一些数据（运行后自动创建）\n\n### 图片标注\n下载labelimg可视化图形标定工具（[点击下载](https://tzutalin.github.io/labelImg/)），Faster R-CNN，YOLO，SSD等目标检测网络所需要的数据集，均需要借此工具标定图像中的目标。生成的 XML 文件是遵循 PASCAL VOC 的格式的。软件打开界面如下：\n\n{% note info %} labelimg一定要放到全英文路径下，否则会报错 {% endnote %}\n软件打开界面如下：\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i6f6385j30vr0madol.jpg)\n软件功能介绍：\n> 按键功能介绍\n> 在labelImg窗口的左边功能键介绍:\n> “Open”是打开单个图像，\n> “Open Dir” 打开文件夹，\n> \"Change Save Dir\" xml标注文件保存的路径，\n> “Next Image” 切换到下一张图像，\n> “Prev Image”切换到上一张图像，\n> “Verify Image”校验图像，\n> “Save”保存图像，\n> “Create RectBox”画标注框一个，\n> “Duplicate RectBox”重复标注框，\n> “Delete RectBox”删除标注框，\n> “Zoom In” 放大图像，\n> “Zoom Out” 缩小图像，\n> “Fit Window”图像适用窗口，\n> “Fit Width”图像适应宽度。\n> 一组快捷键：\n> ![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i8py03vj30jd0ddwhx.jpg)\n> 过程\n> 一般操作的顺序：单张图片的：\n> “open file ” -----\"create rectbox \" -----\"输入类别名称 \"-----“change save dir ”-----\"Save\"\n> 如果多张图片可以open dir先打开一个文件夹，然后change save dir 选择需要存储的文件夹，其余操作如上，保存后即可Next Image跳下一张。\n> 最后在保存文件的路径下生成.xml文件，.xml文件的名字是和标注照片的名字一样，如果要修改已经标注过的图像，.xml中的信息也会随之改变。\n> 得到的.xml 和PASCAL VOC所用格式相同。\n\n下图则是标记好的实例数据，这里我将所有的文字都标记成了同一个label\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40zkqhjsvj30fx0ui7c7.jpg)\n\n\n### 数据集制作\n#### 图片数据集\n- 将所有的图片放到`JPEGImages`文件夹下，在根目录下创建make_txt.py文件，代码如下，运行代码后`ImageSets`中生成数据集分类txt文件\n```python\nimport os\nimport random\ntrainval_percent = 0.1\ntrain_percent = 0.9\nxmlfilepath = 'data/Annotations'\ntxtsavepath = 'data/ImageSets'\ntotal_xml = os.listdir(xmlfilepath)\nnum = len(total_xml)\nlist = range(num)\ntv = int(num * trainval_percent)\ntr = int(tv * train_percent)\ntrainval = random.sample(list, tv)\ntrain = random.sample(trainval, tr)\nftrainval = open('data/ImageSets/trainval.txt', 'w')\nftest = open('data/ImageSets/test.txt', 'w')\nftrain = open('data/ImageSets/train.txt', 'w')\nfval = open('data/ImageSets/val.txt', 'w')\nfor i in list:\n    name = total_xml[i][:-4] + '\\n'\n    if i in trainval:\n        ftrainval.write(name)\n        if i in train:\n            ftest.write(name)\n        else:\n            fval.write(name)\n    else:\n        ftrain.write(name)\nftrainval.close()\nftrain.close()\nfval.close()\nftest.close()\n```\n{% note info no-icon %}\n运行完成后会在ImageSets中看到做好的数据集分类\n{% endnote %}\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h443bznu3lj303f02rglu.jpg)\n#### 标记数据集\n- 将所有个pascal-voc格式的xml文件放入到Annotations文件夹下，根目录下创建 voc_label.py 文件，代码如下。需要注意的是，sets中改为你的sets的名字（make_txt生成的） classes修改为你需要检测的类别，在本案例中，我们只需要检测一种类别\n```python\nimport xml.etree.ElementTree as ET\nimport os\nfrom os import getcwd\n\nsets = ['train', 'test', 'val']\nclasses = ['1']\n\n\ndef convert(size, box):\n    dw = 1. / size[0]\n    dh = 1. / size[1]\n    x = (box[0] + box[1]) / 2.0\n    y = (box[2] + box[3]) / 2.0\n    w = box[1] - box[0]\n    h = box[3] - box[2]\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return x, y, w, h\n\n\ndef convert_annotation(image_id):\n    in_file = open('data/Annotations/%s.xml' % image_id)\n    out_file = open('data/labels/%s.txt' % image_id, 'w')\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find('size')\n    w = int(size.find('width').text)\n    h = int(size.find('height').text)\n    for obj in root.iter('object'):\n        difficult = obj.find('difficult').text\n        cls = obj.find('name').text\n        if cls not in classes or int(difficult) == 1:\n            continue\n        cls_id = classes.index(cls)\n        xmlbox = obj.find('bndbox')\n        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n             float(xmlbox.find('ymax').text))\n        bb = convert((w, h), b)\n        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n\n\nwd = getcwd()\nprint(wd)\nfor image_set in sets:\n    if not os.path.exists('data/labels/'):\n        os.makedirs('data/labels/')\n    image_ids = open('data/ImageSets/%s.txt' % image_set).read().strip().split()\n    list_file = open('data/%s.txt' % image_set, 'w')\n    for image_id in image_ids:\n        list_file.write('data/images/%s.png\\n' % image_id)\n        convert_annotation(image_id)\n    list_file.close()\n```\n{% note info no-icon %}\n运行完成后会在data/label中看到做好的标签文件，并且在data文件下出现了train、val、test的txt文件，保存了图片的路径\n{% endnote %}\n![test.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4459bvkr4j30qa04vwkk.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h445a78m6kj302q01rmx5.jpg)\n\n至此我们训练前期的准备工作差不多已经做完了\n### 调整参数\n接下来需要简单的修改一下配置，就可以开始我们的训练了\n1. 进入到data文件下，修改coco.yaml文件\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4493scqutj30nx030jun.jpg)\n- `path` 为train.txt 、 val.txt与test.txt所在的路径，绝对路径与相对路径均可\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4495wnn78j306o01sgly.jpg)\n- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改\n- `names` 把所有标记的种类写入进来\n\n2. 进入models文件夹，修改五个模型中任意即可\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h44993v12ij303702qt91.jpg)\n- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改\n\n3. 进入根目录，修改train.py文件\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46awu34mbj30qo05ngtk.jpg)\n`weights`，`yaml`，`data`按照自己所需文件的路径修改即可 epochs迭代次数自己决定，我这里仅用100次进行测试 batch-size过高可能会影响电脑运行速度，还是要根据自己电脑硬件条件决定增加还是减少 修改完成，运行即可！\n   \n\n### 开始训练\n激动人心的时刻即将到来，在yolov5根目录运行`python  train.py`，即可看到训练已经开始了。如果运行异常，则需要反查自己的环境以及配置的路径是否有误。\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46e9u1ervj30u10c6nc1.jpg)\n\n训练程序正常后可以在根目录运行`tensorboard --logdir runs/train`， 然后在浏览器打开`localhost:6006`观察，效果如下\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46egunvn4j30sj0jvdln.jpg)\n\n### 结束训练\n漫长的等待之后，训练结束\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gw2qzdjj30uh07ik0c.jpg)\n可以看到文件夹里躺着训练结果\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gyatsmpj30s208o0y2.jpg)\nweights里面静静躺着训练出的模型文件\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gzrer13j30h501gq39.jpg)\n\n### 验证结果\n训练结束之后就需要测试我们的模型识别成功率如何，使用根目录下`detect.py`文件来测试，但是还需要指定一些内容，有以下几种方式可以实现\n1. 命令行运行\n```bash\npython detect.py --weights runs/train/exp17/weights/best.pt --source data/Samples/ --device cpu\n```\n> `weights` 为最终训练出来的模型\n> `source` 为测试图片存放位置\n> `device` 为加载模型使用的设备\n2. pycharm中指定参数\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jjh1ykgj30pk0epq7m.jpg)\n> 在pycharm的配置中添加参数，直接运行即可\n\n运行结束后会在`yolov5\\runs\\detect`路径中查看识别结果，可以看到识别准确率还是非常高的，至此我们的目标识别这一部分就做完了\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jx9pmlpj30i903ywgj.jpg)\n\n## 小图切割\n当大图的训练结束之后，则需要处理小图了。在大量观察后发现小图均有一定的规律，提示要点击的文字均处在同一位置上，那么我们就可以通过最简单的方法：直接指定像素进行图片切割来快速提取出来需要点击的文字\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46kmrmjjxj30q409q462.jpg)\n```python\nfrom PIL import Image\nimport os\n\n\ndef splitimage(img):\n    # 小图切割\n    coordinates_list = [149, 192, 235]  # 需要切割的像素位置\n    result = list()\n    for index, x in enumerate(coordinates_list):\n        box = (x, 1, x + 26, 28)\n        small_pic = img.crop(box)\n        result.append(small_pic)\n    return result\n\n\nbig_img_dir = r'.\\yolov5\\data\\images'  # 大图所在路径\nyolo_img_list = os.listdir(big_img_dir)\n\nfor img_name in yolo_img_list:\n    print(img_name)\n\n    img_name = img_name.split('.')[0]\n    cut_img_list = splitimage(Image.open(fr'small_img/{img_name}.png'))  # 与大图对应的小图进行切割\n    if not os.path.exists(f'./small_img_cut/{img_name}'):\n        os.makedirs(f'./small_img_cut/{img_name}')\n\n    for index, cut_img in enumerate(cut_img_list):\n        cut_img.save(f'./small_img_cut/{img_name}/{index}.png')  # 切割后图片保存\n```\n运行结束后可以看到每个小图已经切割成功，并单独存入单独的文件夹内\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eihrabnj30860c778e.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eisgj0lj309603rt8r.jpg)\n那么这一步小图也处理完成，仅仅剩下最后一步就可以完成识别了\n\n## 孪生网络相似度训练\n### 孪生网络简介\n这里就不过多介绍了，可以直接去大佬github中详细学习[点击进入](https://github.com/bubbliiiing/Siamese-keras)\n### 数据集制作\n这里我对yolov5中的detect.py进行了小小的改动，将识别出来的大图放入到之前切割好的小图中，方便我们后续操作\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47r3g7i0oj30po04rdhy.jpg)\n代码如下：\n```python\nfrom pathlib import Path\nimport cv2\nimport torch\nimport numpy as np\nfrom utils.augmentations import letterbox\nfrom models.common import DetectMultiBackend\nfrom utils.general import check_img_size, non_max_suppression, scale_coords\nfrom utils.plots import save_one_box\n\n\nclass Detect:\n    def __init__(self,\n                 weights='weights/best.pt',  # model.pt path(s)\n                 source='data/Samples',  # file/dir/URL/glob, 0 for webcam\n                 data='data/coco128.yaml',  # dataset.yaml path\n                 imgsz=(640, 640),  # inference size (height, width)\n                 project='runs/detect',  # save results to project/name\n                 ):\n        self.source = str(source)\n        self.weights = weights\n        self.data = data\n        self.imgsz = imgsz\n\n        self.model = None\n\n        self.save_dir = Path(project)  # increment run\n        self.save_dir.mkdir(parents=True, exist_ok=True)  # make dir\n        self.load_model()\n\n    def load_model(self):\n        self.model = DetectMultiBackend(self.weights, data=self.data)\n        stride, names, pt = self.model.stride, self.model.names, self.model.pt\n        imgsz = check_img_size(self.imgsz, s=stride)  # check image size\n        bs = 1  # batch_size\n        self.model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n\n    def identify(self, pic_path):\n        im0s = cv2.imread(pic_path)\n        img = letterbox(im0s)[0]\n        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n        im = np.ascontiguousarray(img)\n        im = torch.from_numpy(im).to().float()\n        im /= 255  # 0 - 255 to 0.0 - 1.0\n        if len(im.shape) == 3:\n            im = im[None]  # expand for batch dim\n\n        pred = self.model(im)\n        pred = non_max_suppression(pred)\n\n        for i, det in enumerate(pred):  # per image\n            im0 = im0s.copy()\n\n            p = Path(pic_path)  # to Path\n            imc = im0.copy()\n            if len(det):\n                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n                for *xyxy, conf, cls in reversed(det):\n                    save_file_path = Path(r'E:\\blog\\deep_learn\\small_img_cut') / p.stem / f'{p.stem}.jpg'\n                    save_one_box(xyxy, imc, file=save_file_path, BGR=True)\n                    # print([i.cpu().detach().numpy().tolist() for i in xyxy])\n\n\nif __name__ == '__main__':\n    import os\n    test = Detect()\n\n    pic_list = os.listdir(r'E:\\blog\\deep_learn\\yolov5\\data\\images')\n    for pic in pic_list:\n        test.identify(fr'E:\\blog\\deep_learn\\big_img\\{pic}')\n```\n接下来需要将相同的文字都放入到一个单独的文件夹内，为了能够快速处理，可以使用一下代码实现。\n```python\nimport time\nimport tkinter\nfrom pathlib import Path\nimport os\nimport cv2\nimport hashlib\nimport random\nimport numpy as np\n\nFILE = Path(__file__).resolve()\nROOT = FILE.parents[0]\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))\nroot = tkinter.Tk()\nroot.title(\"Preview\")\n\nnum = 1\n\n\ndef image_Splicing(data):\n    for big_pic in data['big_pic_path']:\n        for small_pic in data['small_pic_path']:\n\n            cv2.namedWindow('Face', 0)  # 创建一个名为“Face”的窗口用于显示图像\n            cv2.moveWindow('Face', 100, 50)  # 移动窗口到适当位置\n            cv2.resizeWindow('Face', 350, 175)\n            img1 = cv2.imread(str(big_pic))\n            img2 = cv2.imread(str(small_pic))\n\n            img1 = cv2.resize(img1, (640, 640))\n            img2 = cv2.resize(img2, (640, 640))\n            new_img = np.hstack([img1, img2])\n            cv2.imshow('Face', new_img)  # 显示图像\n            cv2.waitKey(100)  # 设置显示时间，1000ms\n            judge = input('是否相同：')\n            if judge:\n                print(big_pic, small_pic)\n                tag_pic(big_pic, small_pic)\n                data['big_pic_path'].remove(big_pic)\n                data['small_pic_path'].remove(small_pic)\n                return image_Splicing(data)\n\n            cv2.destroyWindow('Face')\n\n\ndef get_pic_list():\n    pic_id_list = os.listdir(Path(ROOT / 'small_img_cut'))\n    for pic_id in pic_id_list:\n        pic_list = os.listdir(Path(ROOT / 'small_img_cut' / pic_id))\n        data = {'pic_id': pic_id, 'small_pic_path': [], 'big_pic_path': []}\n        for pic in pic_list:\n            pic_path = Path(ROOT / 'small_img_cut' / pic_id / pic)\n            if len(pic_path.stem) < 5:\n                data['small_pic_path'].append(pic_path)\n            else:\n                data['big_pic_path'].append(pic_path)\n        image_Splicing(data)\n\n\ndef hash():\n    time12 = int(time.time() * 1000)\n    rand04 = random.randint(1000, 9999)\n    return md5(str(time12) + str(rand04))\n\n\ndef md5(*arg):\n    hl = hashlib.md5()\n    line = ''.join(list(map(lambda x: str(x), arg)))\n    hl.update(line.encode(encoding='utf-8'))\n    return hl.hexdigest()\n\n\ndef tag_pic(big_pic, small_pic):\n    global num\n    path = f'./Siamese-pytorch/datasets/images_background/pic{num}'\n    num += 1\n    if not os.path.exists(path):\n        os.mkdir(path)\n\n    big_file = open(big_pic, \"rb\")\n    big_data = big_file.read()\n    big_file.close()\n\n    for i in range(5):\n        new_file = open(f\"{path}/{hash()}.jpg\", \"wb\")\n        new_file.write(big_data)\n        new_file.close()\n\n    small_file = open(small_pic, \"rb\")\n    small_data = small_file.read()\n    small_file.close()\n\n    for i in range(5):\n        new_file = open(f\"{path}/{hash()}.jpg\", \"wb\")\n        new_file.write(small_data)\n        new_file.close()\n\n\nif __name__ == '__main__':\n    get_pic_list()\n```\n运行以上代码后可以看到会显示以下图片\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce2aod6yj309s05raav.jpg)\n并且在控制台会有以下内容\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce33kqxzj302t01d0sl.jpg)\n接下来只需要动动自己那发财的小手，如果相同则输入`1`后回车，如果不相同则直接回车。 就可以看到datasets中开始保存相同的文字图片了\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6854b5yj30ry08in12.jpg)\n接下来的开始训练，结束训练以及验证结果均可以查看大佬的github进行操作，这里直接说结果，可以看到识别准确率还是很高的\n\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6p2ylhnj30gk0aa41t.jpg)\n![image.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6pcl6d1j30gv09f41s.jpg)\n## 结尾\n最后只需要将两个识别方法进行拼接，并删除掉不相关代码，即可实现识别对应问题或图形，也可通过flask来实现接口调用","slug":"深度学习-相似度点选","published":1,"updated":"2022-07-20T02:34:52.513Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl5t021xe0007nkpd5i4a4io3","content":"<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>根据提示依次点击对应文字或图形完成验证。</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3zumbwf57j30o60et440.jpg\" alt=\"test.png\"></p>\n<p>这种验证码由于按照提示顺序进行点击，故不需识别出准确的文字。本文以WPH为例子，只记录使用小图切割+YOLOV5目标识别+相似度来返回指定坐标</p>\n<p><code>url: aHR0cHM6Ly9wYXNzcG9ydC52aXAuY29tL2xvZ2luP3NyYz1odHRwcyUzQSUyRiUyRnd3dy52aXAuY29tJTJG</code></p>\n<h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><p>直接上selenium简单粗暴，从网站上下载一些图片为后续工作做准备</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40hicq5f7j30n50620w0.jpg\" alt=\"test.png\"></p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40hizuusqj30nk056tb1.jpg\" alt=\"test.png\"></p>\n<h2 id=\"YOLO目标识别\"><a href=\"#YOLO目标识别\" class=\"headerlink\" title=\"YOLO目标识别\"></a>YOLO目标识别</h2><h3 id=\"YOLO简介\"><a href=\"#YOLO简介\" class=\"headerlink\" title=\"YOLO简介\"></a>YOLO简介</h3><p>下载yoloV5（<a href=\"https://github.com/ultralytics/yolov5\">点击进入github</a>），或使用<code>Git Bash</code>在指定文件夹目录下输入下面命令行获取：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/ultralytics/yolov5.git</span><br></pre></td></tr></table></figure>\n<p>下载好之后进入yolov5根目录，运行<code>pip install -r requirements.txt</code>安装环境<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h43ypy4kryj305h0ag0v5.jpg\" alt=\"test.png\"></p>\n<blockquote>\n<p>项目文件结构简单说明：<br><code>data</code> 主要放置相关训练数据的配置文件（读取、解析等）<br><code>models</code> 放置各模型的参数配置文件<br><code>weights</code> 放置预训练模型的权重文件<br><code>inference</code> 放置预测&#x2F;推理阶段的测试图片<br><code>runs</code> 放置训练过程中保留下来的一些数据（运行后自动创建）</p>\n</blockquote>\n<h3 id=\"图片标注\"><a href=\"#图片标注\" class=\"headerlink\" title=\"图片标注\"></a>图片标注</h3><p>下载labelimg可视化图形标定工具（<a href=\"https://tzutalin.github.io/labelImg/\">点击下载</a>），Faster R-CNN，YOLO，SSD等目标检测网络所需要的数据集，均需要借此工具标定图像中的目标。生成的 XML 文件是遵循 PASCAL VOC 的格式的。软件打开界面如下：</p>\n<div class=\"note info flat\"><p>labelimg一定要放到全英文路径下，否则会报错 </p>\n</div>\n<p>软件打开界面如下：<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40i6f6385j30vr0madol.jpg\" alt=\"test.png\"><br>软件功能介绍：</p>\n<blockquote>\n<p>按键功能介绍<br>在labelImg窗口的左边功能键介绍:<br>“Open”是打开单个图像，<br>“Open Dir” 打开文件夹，<br>“Change Save Dir” xml标注文件保存的路径，<br>“Next Image” 切换到下一张图像，<br>“Prev Image”切换到上一张图像，<br>“Verify Image”校验图像，<br>“Save”保存图像，<br>“Create RectBox”画标注框一个，<br>“Duplicate RectBox”重复标注框，<br>“Delete RectBox”删除标注框，<br>“Zoom In” 放大图像，<br>“Zoom Out” 缩小图像，<br>“Fit Window”图像适用窗口，<br>“Fit Width”图像适应宽度。<br>一组快捷键：<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40i8py03vj30jd0ddwhx.jpg\" alt=\"test.png\"><br>过程<br>一般操作的顺序：单张图片的：<br>“open file ” —–”create rectbox “ —–”输入类别名称 “—–“change save dir ”—–”Save”<br>如果多张图片可以open dir先打开一个文件夹，然后change save dir 选择需要存储的文件夹，其余操作如上，保存后即可Next Image跳下一张。<br>最后在保存文件的路径下生成.xml文件，.xml文件的名字是和标注照片的名字一样，如果要修改已经标注过的图像，.xml中的信息也会随之改变。<br>得到的.xml 和PASCAL VOC所用格式相同。</p>\n</blockquote>\n<p>下图则是标记好的实例数据，这里我将所有的文字都标记成了同一个label<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40zkqhjsvj30fx0ui7c7.jpg\" alt=\"test.png\"></p>\n<h3 id=\"数据集制作\"><a href=\"#数据集制作\" class=\"headerlink\" title=\"数据集制作\"></a>数据集制作</h3><h4 id=\"图片数据集\"><a href=\"#图片数据集\" class=\"headerlink\" title=\"图片数据集\"></a>图片数据集</h4><ul>\n<li>将所有的图片放到<code>JPEGImages</code>文件夹下，在根目录下创建make_txt.py文件，代码如下，运行代码后<code>ImageSets</code>中生成数据集分类txt文件<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\">trainval_percent = <span class=\"number\">0.1</span></span><br><span class=\"line\">train_percent = <span class=\"number\">0.9</span></span><br><span class=\"line\">xmlfilepath = <span class=\"string\">&#x27;data/Annotations&#x27;</span></span><br><span class=\"line\">txtsavepath = <span class=\"string\">&#x27;data/ImageSets&#x27;</span></span><br><span class=\"line\">total_xml = os.listdir(xmlfilepath)</span><br><span class=\"line\">num = <span class=\"built_in\">len</span>(total_xml)</span><br><span class=\"line\"><span class=\"built_in\">list</span> = <span class=\"built_in\">range</span>(num)</span><br><span class=\"line\">tv = <span class=\"built_in\">int</span>(num * trainval_percent)</span><br><span class=\"line\">tr = <span class=\"built_in\">int</span>(tv * train_percent)</span><br><span class=\"line\">trainval = random.sample(<span class=\"built_in\">list</span>, tv)</span><br><span class=\"line\">train = random.sample(trainval, tr)</span><br><span class=\"line\">ftrainval = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/trainval.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">ftest = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/test.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">ftrain = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/train.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">fval = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/val.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">list</span>:</span><br><span class=\"line\">    name = total_xml[i][:-<span class=\"number\">4</span>] + <span class=\"string\">&#x27;\\n&#x27;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> trainval:</span><br><span class=\"line\">        ftrainval.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> train:</span><br><span class=\"line\">            ftest.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            fval.write(name)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        ftrain.write(name)</span><br><span class=\"line\">ftrainval.close()</span><br><span class=\"line\">ftrain.close()</span><br><span class=\"line\">fval.close()</span><br><span class=\"line\">ftest.close()</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon flat\"><p>运行完成后会在ImageSets中看到做好的数据集分类</p>\n</div>\n<img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h443bznu3lj303f02rglu.jpg\" alt=\"test.png\"></li>\n</ul>\n<h4 id=\"标记数据集\"><a href=\"#标记数据集\" class=\"headerlink\" title=\"标记数据集\"></a>标记数据集</h4><ul>\n<li>将所有个pascal-voc格式的xml文件放入到Annotations文件夹下，根目录下创建 voc_label.py 文件，代码如下。需要注意的是，sets中改为你的sets的名字（make_txt生成的） classes修改为你需要检测的类别，在本案例中，我们只需要检测一种类别<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> xml.etree.ElementTree <span class=\"keyword\">as</span> ET</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> os <span class=\"keyword\">import</span> getcwd</span><br><span class=\"line\"></span><br><span class=\"line\">sets = [<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>, <span class=\"string\">&#x27;val&#x27;</span>]</span><br><span class=\"line\">classes = [<span class=\"string\">&#x27;1&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">convert</span>(<span class=\"params\">size, box</span>):</span><br><span class=\"line\">    dw = <span class=\"number\">1.</span> / size[<span class=\"number\">0</span>]</span><br><span class=\"line\">    dh = <span class=\"number\">1.</span> / size[<span class=\"number\">1</span>]</span><br><span class=\"line\">    x = (box[<span class=\"number\">0</span>] + box[<span class=\"number\">1</span>]) / <span class=\"number\">2.0</span></span><br><span class=\"line\">    y = (box[<span class=\"number\">2</span>] + box[<span class=\"number\">3</span>]) / <span class=\"number\">2.0</span></span><br><span class=\"line\">    w = box[<span class=\"number\">1</span>] - box[<span class=\"number\">0</span>]</span><br><span class=\"line\">    h = box[<span class=\"number\">3</span>] - box[<span class=\"number\">2</span>]</span><br><span class=\"line\">    x = x * dw</span><br><span class=\"line\">    w = w * dw</span><br><span class=\"line\">    y = y * dh</span><br><span class=\"line\">    h = h * dh</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x, y, w, h</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">convert_annotation</span>(<span class=\"params\">image_id</span>):</span><br><span class=\"line\">    in_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/Annotations/%s.xml&#x27;</span> % image_id)</span><br><span class=\"line\">    out_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/labels/%s.txt&#x27;</span> % image_id, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    tree = ET.parse(in_file)</span><br><span class=\"line\">    root = tree.getroot()</span><br><span class=\"line\">    size = root.find(<span class=\"string\">&#x27;size&#x27;</span>)</span><br><span class=\"line\">    w = <span class=\"built_in\">int</span>(size.find(<span class=\"string\">&#x27;width&#x27;</span>).text)</span><br><span class=\"line\">    h = <span class=\"built_in\">int</span>(size.find(<span class=\"string\">&#x27;height&#x27;</span>).text)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> root.<span class=\"built_in\">iter</span>(<span class=\"string\">&#x27;object&#x27;</span>):</span><br><span class=\"line\">        difficult = obj.find(<span class=\"string\">&#x27;difficult&#x27;</span>).text</span><br><span class=\"line\">        cls = obj.find(<span class=\"string\">&#x27;name&#x27;</span>).text</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cls <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> classes <span class=\"keyword\">or</span> <span class=\"built_in\">int</span>(difficult) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        cls_id = classes.index(cls)</span><br><span class=\"line\">        xmlbox = obj.find(<span class=\"string\">&#x27;bndbox&#x27;</span>)</span><br><span class=\"line\">        b = (<span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;xmin&#x27;</span>).text), <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;xmax&#x27;</span>).text), <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;ymin&#x27;</span>).text),</span><br><span class=\"line\">             <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;ymax&#x27;</span>).text))</span><br><span class=\"line\">        bb = convert((w, h), b)</span><br><span class=\"line\">        out_file.write(<span class=\"built_in\">str</span>(cls_id) + <span class=\"string\">&quot; &quot;</span> + <span class=\"string\">&quot; &quot;</span>.join([<span class=\"built_in\">str</span>(a) <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> bb]) + <span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">wd = getcwd()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(wd)</span><br><span class=\"line\"><span class=\"keyword\">for</span> image_set <span class=\"keyword\">in</span> sets:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">&#x27;data/labels/&#x27;</span>):</span><br><span class=\"line\">        os.makedirs(<span class=\"string\">&#x27;data/labels/&#x27;</span>)</span><br><span class=\"line\">    image_ids = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/%s.txt&#x27;</span> % image_set).read().strip().split()</span><br><span class=\"line\">    list_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/%s.txt&#x27;</span> % image_set, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> image_id <span class=\"keyword\">in</span> image_ids:</span><br><span class=\"line\">        list_file.write(<span class=\"string\">&#x27;data/images/%s.png\\n&#x27;</span> % image_id)</span><br><span class=\"line\">        convert_annotation(image_id)</span><br><span class=\"line\">    list_file.close()</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon flat\"><p>运行完成后会在data&#x2F;label中看到做好的标签文件，并且在data文件下出现了train、val、test的txt文件，保存了图片的路径</p>\n</div>\n<img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4459bvkr4j30qa04vwkk.jpg\" alt=\"test.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h445a78m6kj302q01rmx5.jpg\" alt=\"image.png\"></li>\n</ul>\n<p>至此我们训练前期的准备工作差不多已经做完了</p>\n<h3 id=\"调整参数\"><a href=\"#调整参数\" class=\"headerlink\" title=\"调整参数\"></a>调整参数</h3><p>接下来需要简单的修改一下配置，就可以开始我们的训练了</p>\n<ol>\n<li>进入到data文件下，修改coco.yaml文件</li>\n</ol>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4493scqutj30nx030jun.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>path</code> 为train.txt 、 val.txt与test.txt所在的路径，绝对路径与相对路径均可</li>\n</ul>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4495wnn78j306o01sgly.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>nc</code> 为标记种类数，这里我们按照实际标记的种类数进行修改</li>\n<li><code>names</code> 把所有标记的种类写入进来</li>\n</ul>\n<ol start=\"2\">\n<li>进入models文件夹，修改五个模型中任意即可</li>\n</ol>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h44993v12ij303702qt91.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>nc</code> 为标记种类数，这里我们按照实际标记的种类数进行修改</li>\n</ul>\n<ol start=\"3\">\n<li>进入根目录，修改train.py文件<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46awu34mbj30qo05ngtk.jpg\" alt=\"image.png\"><br><code>weights</code>，<code>yaml</code>，<code>data</code>按照自己所需文件的路径修改即可 epochs迭代次数自己决定，我这里仅用100次进行测试 batch-size过高可能会影响电脑运行速度，还是要根据自己电脑硬件条件决定增加还是减少 修改完成，运行即可！</li>\n</ol>\n<h3 id=\"开始训练\"><a href=\"#开始训练\" class=\"headerlink\" title=\"开始训练\"></a>开始训练</h3><p>激动人心的时刻即将到来，在yolov5根目录运行<code>python  train.py</code>，即可看到训练已经开始了。如果运行异常，则需要反查自己的环境以及配置的路径是否有误。<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46e9u1ervj30u10c6nc1.jpg\" alt=\"image.png\"></p>\n<p>训练程序正常后可以在根目录运行<code>tensorboard --logdir runs/train</code>， 然后在浏览器打开<code>localhost:6006</code>观察，效果如下<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46egunvn4j30sj0jvdln.jpg\" alt=\"image.png\"></p>\n<h3 id=\"结束训练\"><a href=\"#结束训练\" class=\"headerlink\" title=\"结束训练\"></a>结束训练</h3><p>漫长的等待之后，训练结束<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gw2qzdjj30uh07ik0c.jpg\" alt=\"image.png\"><br>可以看到文件夹里躺着训练结果<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gyatsmpj30s208o0y2.jpg\" alt=\"image.png\"><br>weights里面静静躺着训练出的模型文件<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gzrer13j30h501gq39.jpg\" alt=\"image.png\"></p>\n<h3 id=\"验证结果\"><a href=\"#验证结果\" class=\"headerlink\" title=\"验证结果\"></a>验证结果</h3><p>训练结束之后就需要测试我们的模型识别成功率如何，使用根目录下<code>detect.py</code>文件来测试，但是还需要指定一些内容，有以下几种方式可以实现</p>\n<ol>\n<li>命令行运行<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python detect.py --weights runs/train/exp17/weights/best.pt --<span class=\"built_in\">source</span> data/Samples/ --device cpu</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><code>weights</code> 为最终训练出来的模型<br><code>source</code> 为测试图片存放位置<br><code>device</code> 为加载模型使用的设备</p>\n</blockquote>\n</li>\n<li>pycharm中指定参数<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46jjh1ykgj30pk0epq7m.jpg\" alt=\"image.png\"><blockquote>\n<p>在pycharm的配置中添加参数，直接运行即可</p>\n</blockquote>\n</li>\n</ol>\n<p>运行结束后会在<code>yolov5\\runs\\detect</code>路径中查看识别结果，可以看到识别准确率还是非常高的，至此我们的目标识别这一部分就做完了<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46jx9pmlpj30i903ywgj.jpg\" alt=\"image.png\"></p>\n<h2 id=\"小图切割\"><a href=\"#小图切割\" class=\"headerlink\" title=\"小图切割\"></a>小图切割</h2><p>当大图的训练结束之后，则需要处理小图了。在大量观察后发现小图均有一定的规律，提示要点击的文字均处在同一位置上，那么我们就可以通过最简单的方法：直接指定像素进行图片切割来快速提取出来需要点击的文字<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46kmrmjjxj30q409q462.jpg\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">splitimage</span>(<span class=\"params\">img</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 小图切割</span></span><br><span class=\"line\">    coordinates_list = [<span class=\"number\">149</span>, <span class=\"number\">192</span>, <span class=\"number\">235</span>]  <span class=\"comment\"># 需要切割的像素位置</span></span><br><span class=\"line\">    result = <span class=\"built_in\">list</span>()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> index, x <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(coordinates_list):</span><br><span class=\"line\">        box = (x, <span class=\"number\">1</span>, x + <span class=\"number\">26</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">        small_pic = img.crop(box)</span><br><span class=\"line\">        result.append(small_pic)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">big_img_dir = <span class=\"string\">r&#x27;.\\yolov5\\data\\images&#x27;</span>  <span class=\"comment\"># 大图所在路径</span></span><br><span class=\"line\">yolo_img_list = os.listdir(big_img_dir)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> img_name <span class=\"keyword\">in</span> yolo_img_list:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(img_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    img_name = img_name.split(<span class=\"string\">&#x27;.&#x27;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    cut_img_list = splitimage(Image.<span class=\"built_in\">open</span>(<span class=\"string\">fr&#x27;small_img/<span class=\"subst\">&#123;img_name&#125;</span>.png&#x27;</span>))  <span class=\"comment\"># 与大图对应的小图进行切割</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>&#x27;</span>):</span><br><span class=\"line\">        os.makedirs(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> index, cut_img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(cut_img_list):</span><br><span class=\"line\">        cut_img.save(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>/<span class=\"subst\">&#123;index&#125;</span>.png&#x27;</span>)  <span class=\"comment\"># 切割后图片保存</span></span><br></pre></td></tr></table></figure>\n<p>运行结束后可以看到每个小图已经切割成功，并单独存入单独的文件夹内<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47eihrabnj30860c778e.jpg\" alt=\"image.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47eisgj0lj309603rt8r.jpg\" alt=\"image.png\"><br>那么这一步小图也处理完成，仅仅剩下最后一步就可以完成识别了</p>\n<h2 id=\"孪生网络相似度训练\"><a href=\"#孪生网络相似度训练\" class=\"headerlink\" title=\"孪生网络相似度训练\"></a>孪生网络相似度训练</h2><h3 id=\"孪生网络简介\"><a href=\"#孪生网络简介\" class=\"headerlink\" title=\"孪生网络简介\"></a>孪生网络简介</h3><p>这里就不过多介绍了，可以直接去大佬github中详细学习<a href=\"https://github.com/bubbliiiing/Siamese-keras\">点击进入</a></p>\n<h3 id=\"数据集制作-1\"><a href=\"#数据集制作-1\" class=\"headerlink\" title=\"数据集制作\"></a>数据集制作</h3><p>这里我对yolov5中的detect.py进行了小小的改动，将识别出来的大图放入到之前切割好的小图中，方便我们后续操作<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47r3g7i0oj30po04rdhy.jpg\" alt=\"image.png\"><br>代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.augmentations <span class=\"keyword\">import</span> letterbox</span><br><span class=\"line\"><span class=\"keyword\">from</span> models.common <span class=\"keyword\">import</span> DetectMultiBackend</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.general <span class=\"keyword\">import</span> check_img_size, non_max_suppression, scale_coords</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.plots <span class=\"keyword\">import</span> save_one_box</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Detect</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self,</span></span><br><span class=\"line\"><span class=\"params\">                 weights=<span class=\"string\">&#x27;weights/best.pt&#x27;</span>,  <span class=\"comment\"># model.pt path(s)</span></span></span><br><span class=\"line\"><span class=\"params\">                 source=<span class=\"string\">&#x27;data/Samples&#x27;</span>,  <span class=\"comment\"># file/dir/URL/glob, 0 for webcam</span></span></span><br><span class=\"line\"><span class=\"params\">                 data=<span class=\"string\">&#x27;data/coco128.yaml&#x27;</span>,  <span class=\"comment\"># dataset.yaml path</span></span></span><br><span class=\"line\"><span class=\"params\">                 imgsz=(<span class=\"params\"><span class=\"number\">640</span>, <span class=\"number\">640</span></span>),  <span class=\"comment\"># inference size (height, width)</span></span></span><br><span class=\"line\"><span class=\"params\">                 project=<span class=\"string\">&#x27;runs/detect&#x27;</span>,  <span class=\"comment\"># save results to project/name</span></span></span><br><span class=\"line\"><span class=\"params\">                 </span>):</span><br><span class=\"line\">        self.source = <span class=\"built_in\">str</span>(source)</span><br><span class=\"line\">        self.weights = weights</span><br><span class=\"line\">        self.data = data</span><br><span class=\"line\">        self.imgsz = imgsz</span><br><span class=\"line\"></span><br><span class=\"line\">        self.model = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">        self.save_dir = Path(project)  <span class=\"comment\"># increment run</span></span><br><span class=\"line\">        self.save_dir.mkdir(parents=<span class=\"literal\">True</span>, exist_ok=<span class=\"literal\">True</span>)  <span class=\"comment\"># make dir</span></span><br><span class=\"line\">        self.load_model()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">load_model</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.model = DetectMultiBackend(self.weights, data=self.data)</span><br><span class=\"line\">        stride, names, pt = self.model.stride, self.model.names, self.model.pt</span><br><span class=\"line\">        imgsz = check_img_size(self.imgsz, s=stride)  <span class=\"comment\"># check image size</span></span><br><span class=\"line\">        bs = <span class=\"number\">1</span>  <span class=\"comment\"># batch_size</span></span><br><span class=\"line\">        self.model.warmup(imgsz=(<span class=\"number\">1</span> <span class=\"keyword\">if</span> pt <span class=\"keyword\">else</span> bs, <span class=\"number\">3</span>, *imgsz))  <span class=\"comment\"># warmup</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">identify</span>(<span class=\"params\">self, pic_path</span>):</span><br><span class=\"line\">        im0s = cv2.imread(pic_path)</span><br><span class=\"line\">        img = letterbox(im0s)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        img = img.transpose((<span class=\"number\">2</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>))[::-<span class=\"number\">1</span>]  <span class=\"comment\"># HWC to CHW, BGR to RGB</span></span><br><span class=\"line\">        im = np.ascontiguousarray(img)</span><br><span class=\"line\">        im = torch.from_numpy(im).to().<span class=\"built_in\">float</span>()</span><br><span class=\"line\">        im /= <span class=\"number\">255</span>  <span class=\"comment\"># 0 - 255 to 0.0 - 1.0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(im.shape) == <span class=\"number\">3</span>:</span><br><span class=\"line\">            im = im[<span class=\"literal\">None</span>]  <span class=\"comment\"># expand for batch dim</span></span><br><span class=\"line\"></span><br><span class=\"line\">        pred = self.model(im)</span><br><span class=\"line\">        pred = non_max_suppression(pred)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, det <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(pred):  <span class=\"comment\"># per image</span></span><br><span class=\"line\">            im0 = im0s.copy()</span><br><span class=\"line\"></span><br><span class=\"line\">            p = Path(pic_path)  <span class=\"comment\"># to Path</span></span><br><span class=\"line\">            imc = im0.copy()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(det):</span><br><span class=\"line\">                det[:, :<span class=\"number\">4</span>] = scale_coords(im.shape[<span class=\"number\">2</span>:], det[:, :<span class=\"number\">4</span>], im0.shape).<span class=\"built_in\">round</span>()</span><br><span class=\"line\">                <span class=\"keyword\">for</span> *xyxy, conf, cls <span class=\"keyword\">in</span> <span class=\"built_in\">reversed</span>(det):</span><br><span class=\"line\">                    save_file_path = Path(<span class=\"string\">r&#x27;E:\\blog\\deep_learn\\small_img_cut&#x27;</span>) / p.stem / <span class=\"string\">f&#x27;<span class=\"subst\">&#123;p.stem&#125;</span>.jpg&#x27;</span></span><br><span class=\"line\">                    save_one_box(xyxy, imc, file=save_file_path, BGR=<span class=\"literal\">True</span>)</span><br><span class=\"line\">                    <span class=\"comment\"># print([i.cpu().detach().numpy().tolist() for i in xyxy])</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> os</span><br><span class=\"line\">    test = Detect()</span><br><span class=\"line\"></span><br><span class=\"line\">    pic_list = os.listdir(<span class=\"string\">r&#x27;E:\\blog\\deep_learn\\yolov5\\data\\images&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> pic <span class=\"keyword\">in</span> pic_list:</span><br><span class=\"line\">        test.identify(<span class=\"string\">fr&#x27;E:\\blog\\deep_learn\\big_img\\&#123;pic&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>接下来需要将相同的文字都放入到一个单独的文件夹内，为了能够快速处理，可以使用一下代码实现。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter</span><br><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> hashlib</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">FILE = Path(__file__).resolve()</span><br><span class=\"line\">ROOT = FILE.parents[<span class=\"number\">0</span>]</span><br><span class=\"line\">ROOT = Path(os.path.relpath(ROOT, Path.cwd()))</span><br><span class=\"line\">root = tkinter.Tk()</span><br><span class=\"line\">root.title(<span class=\"string\">&quot;Preview&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">num = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">image_Splicing</span>(<span class=\"params\">data</span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> big_pic <span class=\"keyword\">in</span> data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>]:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_pic <span class=\"keyword\">in</span> data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>]:</span><br><span class=\"line\"></span><br><span class=\"line\">            cv2.namedWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">0</span>)  <span class=\"comment\"># 创建一个名为“Face”的窗口用于显示图像</span></span><br><span class=\"line\">            cv2.moveWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">100</span>, <span class=\"number\">50</span>)  <span class=\"comment\"># 移动窗口到适当位置</span></span><br><span class=\"line\">            cv2.resizeWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">350</span>, <span class=\"number\">175</span>)</span><br><span class=\"line\">            img1 = cv2.imread(<span class=\"built_in\">str</span>(big_pic))</span><br><span class=\"line\">            img2 = cv2.imread(<span class=\"built_in\">str</span>(small_pic))</span><br><span class=\"line\"></span><br><span class=\"line\">            img1 = cv2.resize(img1, (<span class=\"number\">640</span>, <span class=\"number\">640</span>))</span><br><span class=\"line\">            img2 = cv2.resize(img2, (<span class=\"number\">640</span>, <span class=\"number\">640</span>))</span><br><span class=\"line\">            new_img = np.hstack([img1, img2])</span><br><span class=\"line\">            cv2.imshow(<span class=\"string\">&#x27;Face&#x27;</span>, new_img)  <span class=\"comment\"># 显示图像</span></span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">100</span>)  <span class=\"comment\"># 设置显示时间，1000ms</span></span><br><span class=\"line\">            judge = <span class=\"built_in\">input</span>(<span class=\"string\">&#x27;是否相同：&#x27;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> judge:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(big_pic, small_pic)</span><br><span class=\"line\">                tag_pic(big_pic, small_pic)</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>].remove(big_pic)</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>].remove(small_pic)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> image_Splicing(data)</span><br><span class=\"line\"></span><br><span class=\"line\">            cv2.destroyWindow(<span class=\"string\">&#x27;Face&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_pic_list</span>():</span><br><span class=\"line\">    pic_id_list = os.listdir(Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> pic_id <span class=\"keyword\">in</span> pic_id_list:</span><br><span class=\"line\">        pic_list = os.listdir(Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span> / pic_id))</span><br><span class=\"line\">        data = &#123;<span class=\"string\">&#x27;pic_id&#x27;</span>: pic_id, <span class=\"string\">&#x27;small_pic_path&#x27;</span>: [], <span class=\"string\">&#x27;big_pic_path&#x27;</span>: []&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> pic <span class=\"keyword\">in</span> pic_list:</span><br><span class=\"line\">            pic_path = Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span> / pic_id / pic)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(pic_path.stem) &lt; <span class=\"number\">5</span>:</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>].append(pic_path)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>].append(pic_path)</span><br><span class=\"line\">        image_Splicing(data)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hash</span>():</span><br><span class=\"line\">    time12 = <span class=\"built_in\">int</span>(time.time() * <span class=\"number\">1000</span>)</span><br><span class=\"line\">    rand04 = random.randint(<span class=\"number\">1000</span>, <span class=\"number\">9999</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> md5(<span class=\"built_in\">str</span>(time12) + <span class=\"built_in\">str</span>(rand04))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">md5</span>(<span class=\"params\">*arg</span>):</span><br><span class=\"line\">    hl = hashlib.md5()</span><br><span class=\"line\">    line = <span class=\"string\">&#x27;&#x27;</span>.join(<span class=\"built_in\">list</span>(<span class=\"built_in\">map</span>(<span class=\"keyword\">lambda</span> x: <span class=\"built_in\">str</span>(x), arg)))</span><br><span class=\"line\">    hl.update(line.encode(encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> hl.hexdigest()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tag_pic</span>(<span class=\"params\">big_pic, small_pic</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> num</span><br><span class=\"line\">    path = <span class=\"string\">f&#x27;./Siamese-pytorch/datasets/images_background/pic<span class=\"subst\">&#123;num&#125;</span>&#x27;</span></span><br><span class=\"line\">    num += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(path):</span><br><span class=\"line\">        os.mkdir(path)</span><br><span class=\"line\"></span><br><span class=\"line\">    big_file = <span class=\"built_in\">open</span>(big_pic, <span class=\"string\">&quot;rb&quot;</span>)</span><br><span class=\"line\">    big_data = big_file.read()</span><br><span class=\"line\">    big_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        new_file = <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;path&#125;</span>/<span class=\"subst\">&#123;<span class=\"built_in\">hash</span>()&#125;</span>.jpg&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>)</span><br><span class=\"line\">        new_file.write(big_data)</span><br><span class=\"line\">        new_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    small_file = <span class=\"built_in\">open</span>(small_pic, <span class=\"string\">&quot;rb&quot;</span>)</span><br><span class=\"line\">    small_data = small_file.read()</span><br><span class=\"line\">    small_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        new_file = <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;path&#125;</span>/<span class=\"subst\">&#123;<span class=\"built_in\">hash</span>()&#125;</span>.jpg&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>)</span><br><span class=\"line\">        new_file.write(small_data)</span><br><span class=\"line\">        new_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    get_pic_list()</span><br></pre></td></tr></table></figure>\n<p>运行以上代码后可以看到会显示以下图片<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4ce2aod6yj309s05raav.jpg\" alt=\"image.png\"><br>并且在控制台会有以下内容<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4ce33kqxzj302t01d0sl.jpg\" alt=\"image.png\"><br>接下来只需要动动自己那发财的小手，如果相同则输入<code>1</code>后回车，如果不相同则直接回车。 就可以看到datasets中开始保存相同的文字图片了<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6854b5yj30ry08in12.jpg\" alt=\"image.png\"><br>接下来的开始训练，结束训练以及验证结果均可以查看大佬的github进行操作，这里直接说结果，可以看到识别准确率还是很高的</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6p2ylhnj30gk0aa41t.jpg\" alt=\"image.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6pcl6d1j30gv09f41s.jpg\" alt=\"image.png\"></p>\n<h2 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h2><p>最后只需要将两个识别方法进行拼接，并删除掉不相关代码，即可实现识别对应问题或图形，也可通过flask来实现接口调用</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>根据提示依次点击对应文字或图形完成验证。</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h3zumbwf57j30o60et440.jpg\" alt=\"test.png\"></p>\n<p>这种验证码由于按照提示顺序进行点击，故不需识别出准确的文字。本文以WPH为例子，只记录使用小图切割+YOLOV5目标识别+相似度来返回指定坐标</p>\n<p><code>url: aHR0cHM6Ly9wYXNzcG9ydC52aXAuY29tL2xvZ2luP3NyYz1odHRwcyUzQSUyRiUyRnd3dy52aXAuY29tJTJG</code></p>\n<h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><p>直接上selenium简单粗暴，从网站上下载一些图片为后续工作做准备</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40hicq5f7j30n50620w0.jpg\" alt=\"test.png\"></p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40hizuusqj30nk056tb1.jpg\" alt=\"test.png\"></p>\n<h2 id=\"YOLO目标识别\"><a href=\"#YOLO目标识别\" class=\"headerlink\" title=\"YOLO目标识别\"></a>YOLO目标识别</h2><h3 id=\"YOLO简介\"><a href=\"#YOLO简介\" class=\"headerlink\" title=\"YOLO简介\"></a>YOLO简介</h3><p>下载yoloV5（<a href=\"https://github.com/ultralytics/yolov5\">点击进入github</a>），或使用<code>Git Bash</code>在指定文件夹目录下输入下面命令行获取：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/ultralytics/yolov5.git</span><br></pre></td></tr></table></figure>\n<p>下载好之后进入yolov5根目录，运行<code>pip install -r requirements.txt</code>安装环境<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h43ypy4kryj305h0ag0v5.jpg\" alt=\"test.png\"></p>\n<blockquote>\n<p>项目文件结构简单说明：<br><code>data</code> 主要放置相关训练数据的配置文件（读取、解析等）<br><code>models</code> 放置各模型的参数配置文件<br><code>weights</code> 放置预训练模型的权重文件<br><code>inference</code> 放置预测&#x2F;推理阶段的测试图片<br><code>runs</code> 放置训练过程中保留下来的一些数据（运行后自动创建）</p>\n</blockquote>\n<h3 id=\"图片标注\"><a href=\"#图片标注\" class=\"headerlink\" title=\"图片标注\"></a>图片标注</h3><p>下载labelimg可视化图形标定工具（<a href=\"https://tzutalin.github.io/labelImg/\">点击下载</a>），Faster R-CNN，YOLO，SSD等目标检测网络所需要的数据集，均需要借此工具标定图像中的目标。生成的 XML 文件是遵循 PASCAL VOC 的格式的。软件打开界面如下：</p>\n<div class=\"note info flat\"><p>labelimg一定要放到全英文路径下，否则会报错 </p>\n</div>\n<p>软件打开界面如下：<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40i6f6385j30vr0madol.jpg\" alt=\"test.png\"><br>软件功能介绍：</p>\n<blockquote>\n<p>按键功能介绍<br>在labelImg窗口的左边功能键介绍:<br>“Open”是打开单个图像，<br>“Open Dir” 打开文件夹，<br>“Change Save Dir” xml标注文件保存的路径，<br>“Next Image” 切换到下一张图像，<br>“Prev Image”切换到上一张图像，<br>“Verify Image”校验图像，<br>“Save”保存图像，<br>“Create RectBox”画标注框一个，<br>“Duplicate RectBox”重复标注框，<br>“Delete RectBox”删除标注框，<br>“Zoom In” 放大图像，<br>“Zoom Out” 缩小图像，<br>“Fit Window”图像适用窗口，<br>“Fit Width”图像适应宽度。<br>一组快捷键：<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40i8py03vj30jd0ddwhx.jpg\" alt=\"test.png\"><br>过程<br>一般操作的顺序：单张图片的：<br>“open file ” —–”create rectbox “ —–”输入类别名称 “—–“change save dir ”—–”Save”<br>如果多张图片可以open dir先打开一个文件夹，然后change save dir 选择需要存储的文件夹，其余操作如上，保存后即可Next Image跳下一张。<br>最后在保存文件的路径下生成.xml文件，.xml文件的名字是和标注照片的名字一样，如果要修改已经标注过的图像，.xml中的信息也会随之改变。<br>得到的.xml 和PASCAL VOC所用格式相同。</p>\n</blockquote>\n<p>下图则是标记好的实例数据，这里我将所有的文字都标记成了同一个label<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h40zkqhjsvj30fx0ui7c7.jpg\" alt=\"test.png\"></p>\n<h3 id=\"数据集制作\"><a href=\"#数据集制作\" class=\"headerlink\" title=\"数据集制作\"></a>数据集制作</h3><h4 id=\"图片数据集\"><a href=\"#图片数据集\" class=\"headerlink\" title=\"图片数据集\"></a>图片数据集</h4><ul>\n<li>将所有的图片放到<code>JPEGImages</code>文件夹下，在根目录下创建make_txt.py文件，代码如下，运行代码后<code>ImageSets</code>中生成数据集分类txt文件<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\">trainval_percent = <span class=\"number\">0.1</span></span><br><span class=\"line\">train_percent = <span class=\"number\">0.9</span></span><br><span class=\"line\">xmlfilepath = <span class=\"string\">&#x27;data/Annotations&#x27;</span></span><br><span class=\"line\">txtsavepath = <span class=\"string\">&#x27;data/ImageSets&#x27;</span></span><br><span class=\"line\">total_xml = os.listdir(xmlfilepath)</span><br><span class=\"line\">num = <span class=\"built_in\">len</span>(total_xml)</span><br><span class=\"line\"><span class=\"built_in\">list</span> = <span class=\"built_in\">range</span>(num)</span><br><span class=\"line\">tv = <span class=\"built_in\">int</span>(num * trainval_percent)</span><br><span class=\"line\">tr = <span class=\"built_in\">int</span>(tv * train_percent)</span><br><span class=\"line\">trainval = random.sample(<span class=\"built_in\">list</span>, tv)</span><br><span class=\"line\">train = random.sample(trainval, tr)</span><br><span class=\"line\">ftrainval = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/trainval.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">ftest = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/test.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">ftrain = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/train.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">fval = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/val.txt&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">list</span>:</span><br><span class=\"line\">    name = total_xml[i][:-<span class=\"number\">4</span>] + <span class=\"string\">&#x27;\\n&#x27;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> trainval:</span><br><span class=\"line\">        ftrainval.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> train:</span><br><span class=\"line\">            ftest.write(name)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            fval.write(name)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        ftrain.write(name)</span><br><span class=\"line\">ftrainval.close()</span><br><span class=\"line\">ftrain.close()</span><br><span class=\"line\">fval.close()</span><br><span class=\"line\">ftest.close()</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon flat\"><p>运行完成后会在ImageSets中看到做好的数据集分类</p>\n</div>\n<img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h443bznu3lj303f02rglu.jpg\" alt=\"test.png\"></li>\n</ul>\n<h4 id=\"标记数据集\"><a href=\"#标记数据集\" class=\"headerlink\" title=\"标记数据集\"></a>标记数据集</h4><ul>\n<li>将所有个pascal-voc格式的xml文件放入到Annotations文件夹下，根目录下创建 voc_label.py 文件，代码如下。需要注意的是，sets中改为你的sets的名字（make_txt生成的） classes修改为你需要检测的类别，在本案例中，我们只需要检测一种类别<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> xml.etree.ElementTree <span class=\"keyword\">as</span> ET</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> os <span class=\"keyword\">import</span> getcwd</span><br><span class=\"line\"></span><br><span class=\"line\">sets = [<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;test&#x27;</span>, <span class=\"string\">&#x27;val&#x27;</span>]</span><br><span class=\"line\">classes = [<span class=\"string\">&#x27;1&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">convert</span>(<span class=\"params\">size, box</span>):</span><br><span class=\"line\">    dw = <span class=\"number\">1.</span> / size[<span class=\"number\">0</span>]</span><br><span class=\"line\">    dh = <span class=\"number\">1.</span> / size[<span class=\"number\">1</span>]</span><br><span class=\"line\">    x = (box[<span class=\"number\">0</span>] + box[<span class=\"number\">1</span>]) / <span class=\"number\">2.0</span></span><br><span class=\"line\">    y = (box[<span class=\"number\">2</span>] + box[<span class=\"number\">3</span>]) / <span class=\"number\">2.0</span></span><br><span class=\"line\">    w = box[<span class=\"number\">1</span>] - box[<span class=\"number\">0</span>]</span><br><span class=\"line\">    h = box[<span class=\"number\">3</span>] - box[<span class=\"number\">2</span>]</span><br><span class=\"line\">    x = x * dw</span><br><span class=\"line\">    w = w * dw</span><br><span class=\"line\">    y = y * dh</span><br><span class=\"line\">    h = h * dh</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x, y, w, h</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">convert_annotation</span>(<span class=\"params\">image_id</span>):</span><br><span class=\"line\">    in_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/Annotations/%s.xml&#x27;</span> % image_id)</span><br><span class=\"line\">    out_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/labels/%s.txt&#x27;</span> % image_id, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    tree = ET.parse(in_file)</span><br><span class=\"line\">    root = tree.getroot()</span><br><span class=\"line\">    size = root.find(<span class=\"string\">&#x27;size&#x27;</span>)</span><br><span class=\"line\">    w = <span class=\"built_in\">int</span>(size.find(<span class=\"string\">&#x27;width&#x27;</span>).text)</span><br><span class=\"line\">    h = <span class=\"built_in\">int</span>(size.find(<span class=\"string\">&#x27;height&#x27;</span>).text)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> root.<span class=\"built_in\">iter</span>(<span class=\"string\">&#x27;object&#x27;</span>):</span><br><span class=\"line\">        difficult = obj.find(<span class=\"string\">&#x27;difficult&#x27;</span>).text</span><br><span class=\"line\">        cls = obj.find(<span class=\"string\">&#x27;name&#x27;</span>).text</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cls <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> classes <span class=\"keyword\">or</span> <span class=\"built_in\">int</span>(difficult) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        cls_id = classes.index(cls)</span><br><span class=\"line\">        xmlbox = obj.find(<span class=\"string\">&#x27;bndbox&#x27;</span>)</span><br><span class=\"line\">        b = (<span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;xmin&#x27;</span>).text), <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;xmax&#x27;</span>).text), <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;ymin&#x27;</span>).text),</span><br><span class=\"line\">             <span class=\"built_in\">float</span>(xmlbox.find(<span class=\"string\">&#x27;ymax&#x27;</span>).text))</span><br><span class=\"line\">        bb = convert((w, h), b)</span><br><span class=\"line\">        out_file.write(<span class=\"built_in\">str</span>(cls_id) + <span class=\"string\">&quot; &quot;</span> + <span class=\"string\">&quot; &quot;</span>.join([<span class=\"built_in\">str</span>(a) <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> bb]) + <span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">wd = getcwd()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(wd)</span><br><span class=\"line\"><span class=\"keyword\">for</span> image_set <span class=\"keyword\">in</span> sets:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">&#x27;data/labels/&#x27;</span>):</span><br><span class=\"line\">        os.makedirs(<span class=\"string\">&#x27;data/labels/&#x27;</span>)</span><br><span class=\"line\">    image_ids = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/ImageSets/%s.txt&#x27;</span> % image_set).read().strip().split()</span><br><span class=\"line\">    list_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;data/%s.txt&#x27;</span> % image_set, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> image_id <span class=\"keyword\">in</span> image_ids:</span><br><span class=\"line\">        list_file.write(<span class=\"string\">&#x27;data/images/%s.png\\n&#x27;</span> % image_id)</span><br><span class=\"line\">        convert_annotation(image_id)</span><br><span class=\"line\">    list_file.close()</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon flat\"><p>运行完成后会在data&#x2F;label中看到做好的标签文件，并且在data文件下出现了train、val、test的txt文件，保存了图片的路径</p>\n</div>\n<img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4459bvkr4j30qa04vwkk.jpg\" alt=\"test.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h445a78m6kj302q01rmx5.jpg\" alt=\"image.png\"></li>\n</ul>\n<p>至此我们训练前期的准备工作差不多已经做完了</p>\n<h3 id=\"调整参数\"><a href=\"#调整参数\" class=\"headerlink\" title=\"调整参数\"></a>调整参数</h3><p>接下来需要简单的修改一下配置，就可以开始我们的训练了</p>\n<ol>\n<li>进入到data文件下，修改coco.yaml文件</li>\n</ol>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4493scqutj30nx030jun.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>path</code> 为train.txt 、 val.txt与test.txt所在的路径，绝对路径与相对路径均可</li>\n</ul>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4495wnn78j306o01sgly.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>nc</code> 为标记种类数，这里我们按照实际标记的种类数进行修改</li>\n<li><code>names</code> 把所有标记的种类写入进来</li>\n</ul>\n<ol start=\"2\">\n<li>进入models文件夹，修改五个模型中任意即可</li>\n</ol>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h44993v12ij303702qt91.jpg\" alt=\"image.png\"></p>\n<ul>\n<li><code>nc</code> 为标记种类数，这里我们按照实际标记的种类数进行修改</li>\n</ul>\n<ol start=\"3\">\n<li>进入根目录，修改train.py文件<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46awu34mbj30qo05ngtk.jpg\" alt=\"image.png\"><br><code>weights</code>，<code>yaml</code>，<code>data</code>按照自己所需文件的路径修改即可 epochs迭代次数自己决定，我这里仅用100次进行测试 batch-size过高可能会影响电脑运行速度，还是要根据自己电脑硬件条件决定增加还是减少 修改完成，运行即可！</li>\n</ol>\n<h3 id=\"开始训练\"><a href=\"#开始训练\" class=\"headerlink\" title=\"开始训练\"></a>开始训练</h3><p>激动人心的时刻即将到来，在yolov5根目录运行<code>python  train.py</code>，即可看到训练已经开始了。如果运行异常，则需要反查自己的环境以及配置的路径是否有误。<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46e9u1ervj30u10c6nc1.jpg\" alt=\"image.png\"></p>\n<p>训练程序正常后可以在根目录运行<code>tensorboard --logdir runs/train</code>， 然后在浏览器打开<code>localhost:6006</code>观察，效果如下<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46egunvn4j30sj0jvdln.jpg\" alt=\"image.png\"></p>\n<h3 id=\"结束训练\"><a href=\"#结束训练\" class=\"headerlink\" title=\"结束训练\"></a>结束训练</h3><p>漫长的等待之后，训练结束<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gw2qzdjj30uh07ik0c.jpg\" alt=\"image.png\"><br>可以看到文件夹里躺着训练结果<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gyatsmpj30s208o0y2.jpg\" alt=\"image.png\"><br>weights里面静静躺着训练出的模型文件<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46gzrer13j30h501gq39.jpg\" alt=\"image.png\"></p>\n<h3 id=\"验证结果\"><a href=\"#验证结果\" class=\"headerlink\" title=\"验证结果\"></a>验证结果</h3><p>训练结束之后就需要测试我们的模型识别成功率如何，使用根目录下<code>detect.py</code>文件来测试，但是还需要指定一些内容，有以下几种方式可以实现</p>\n<ol>\n<li>命令行运行<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python detect.py --weights runs/train/exp17/weights/best.pt --<span class=\"built_in\">source</span> data/Samples/ --device cpu</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><code>weights</code> 为最终训练出来的模型<br><code>source</code> 为测试图片存放位置<br><code>device</code> 为加载模型使用的设备</p>\n</blockquote>\n</li>\n<li>pycharm中指定参数<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46jjh1ykgj30pk0epq7m.jpg\" alt=\"image.png\"><blockquote>\n<p>在pycharm的配置中添加参数，直接运行即可</p>\n</blockquote>\n</li>\n</ol>\n<p>运行结束后会在<code>yolov5\\runs\\detect</code>路径中查看识别结果，可以看到识别准确率还是非常高的，至此我们的目标识别这一部分就做完了<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46jx9pmlpj30i903ywgj.jpg\" alt=\"image.png\"></p>\n<h2 id=\"小图切割\"><a href=\"#小图切割\" class=\"headerlink\" title=\"小图切割\"></a>小图切割</h2><p>当大图的训练结束之后，则需要处理小图了。在大量观察后发现小图均有一定的规律，提示要点击的文字均处在同一位置上，那么我们就可以通过最简单的方法：直接指定像素进行图片切割来快速提取出来需要点击的文字<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h46kmrmjjxj30q409q462.jpg\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">splitimage</span>(<span class=\"params\">img</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 小图切割</span></span><br><span class=\"line\">    coordinates_list = [<span class=\"number\">149</span>, <span class=\"number\">192</span>, <span class=\"number\">235</span>]  <span class=\"comment\"># 需要切割的像素位置</span></span><br><span class=\"line\">    result = <span class=\"built_in\">list</span>()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> index, x <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(coordinates_list):</span><br><span class=\"line\">        box = (x, <span class=\"number\">1</span>, x + <span class=\"number\">26</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\">        small_pic = img.crop(box)</span><br><span class=\"line\">        result.append(small_pic)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">big_img_dir = <span class=\"string\">r&#x27;.\\yolov5\\data\\images&#x27;</span>  <span class=\"comment\"># 大图所在路径</span></span><br><span class=\"line\">yolo_img_list = os.listdir(big_img_dir)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> img_name <span class=\"keyword\">in</span> yolo_img_list:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(img_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    img_name = img_name.split(<span class=\"string\">&#x27;.&#x27;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    cut_img_list = splitimage(Image.<span class=\"built_in\">open</span>(<span class=\"string\">fr&#x27;small_img/<span class=\"subst\">&#123;img_name&#125;</span>.png&#x27;</span>))  <span class=\"comment\"># 与大图对应的小图进行切割</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>&#x27;</span>):</span><br><span class=\"line\">        os.makedirs(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> index, cut_img <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(cut_img_list):</span><br><span class=\"line\">        cut_img.save(<span class=\"string\">f&#x27;./small_img_cut/<span class=\"subst\">&#123;img_name&#125;</span>/<span class=\"subst\">&#123;index&#125;</span>.png&#x27;</span>)  <span class=\"comment\"># 切割后图片保存</span></span><br></pre></td></tr></table></figure>\n<p>运行结束后可以看到每个小图已经切割成功，并单独存入单独的文件夹内<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47eihrabnj30860c778e.jpg\" alt=\"image.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47eisgj0lj309603rt8r.jpg\" alt=\"image.png\"><br>那么这一步小图也处理完成，仅仅剩下最后一步就可以完成识别了</p>\n<h2 id=\"孪生网络相似度训练\"><a href=\"#孪生网络相似度训练\" class=\"headerlink\" title=\"孪生网络相似度训练\"></a>孪生网络相似度训练</h2><h3 id=\"孪生网络简介\"><a href=\"#孪生网络简介\" class=\"headerlink\" title=\"孪生网络简介\"></a>孪生网络简介</h3><p>这里就不过多介绍了，可以直接去大佬github中详细学习<a href=\"https://github.com/bubbliiiing/Siamese-keras\">点击进入</a></p>\n<h3 id=\"数据集制作-1\"><a href=\"#数据集制作-1\" class=\"headerlink\" title=\"数据集制作\"></a>数据集制作</h3><p>这里我对yolov5中的detect.py进行了小小的改动，将识别出来的大图放入到之前切割好的小图中，方便我们后续操作<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h47r3g7i0oj30po04rdhy.jpg\" alt=\"image.png\"><br>代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.augmentations <span class=\"keyword\">import</span> letterbox</span><br><span class=\"line\"><span class=\"keyword\">from</span> models.common <span class=\"keyword\">import</span> DetectMultiBackend</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.general <span class=\"keyword\">import</span> check_img_size, non_max_suppression, scale_coords</span><br><span class=\"line\"><span class=\"keyword\">from</span> utils.plots <span class=\"keyword\">import</span> save_one_box</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Detect</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self,</span></span><br><span class=\"line\"><span class=\"params\">                 weights=<span class=\"string\">&#x27;weights/best.pt&#x27;</span>,  <span class=\"comment\"># model.pt path(s)</span></span></span><br><span class=\"line\"><span class=\"params\">                 source=<span class=\"string\">&#x27;data/Samples&#x27;</span>,  <span class=\"comment\"># file/dir/URL/glob, 0 for webcam</span></span></span><br><span class=\"line\"><span class=\"params\">                 data=<span class=\"string\">&#x27;data/coco128.yaml&#x27;</span>,  <span class=\"comment\"># dataset.yaml path</span></span></span><br><span class=\"line\"><span class=\"params\">                 imgsz=(<span class=\"params\"><span class=\"number\">640</span>, <span class=\"number\">640</span></span>),  <span class=\"comment\"># inference size (height, width)</span></span></span><br><span class=\"line\"><span class=\"params\">                 project=<span class=\"string\">&#x27;runs/detect&#x27;</span>,  <span class=\"comment\"># save results to project/name</span></span></span><br><span class=\"line\"><span class=\"params\">                 </span>):</span><br><span class=\"line\">        self.source = <span class=\"built_in\">str</span>(source)</span><br><span class=\"line\">        self.weights = weights</span><br><span class=\"line\">        self.data = data</span><br><span class=\"line\">        self.imgsz = imgsz</span><br><span class=\"line\"></span><br><span class=\"line\">        self.model = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">        self.save_dir = Path(project)  <span class=\"comment\"># increment run</span></span><br><span class=\"line\">        self.save_dir.mkdir(parents=<span class=\"literal\">True</span>, exist_ok=<span class=\"literal\">True</span>)  <span class=\"comment\"># make dir</span></span><br><span class=\"line\">        self.load_model()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">load_model</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.model = DetectMultiBackend(self.weights, data=self.data)</span><br><span class=\"line\">        stride, names, pt = self.model.stride, self.model.names, self.model.pt</span><br><span class=\"line\">        imgsz = check_img_size(self.imgsz, s=stride)  <span class=\"comment\"># check image size</span></span><br><span class=\"line\">        bs = <span class=\"number\">1</span>  <span class=\"comment\"># batch_size</span></span><br><span class=\"line\">        self.model.warmup(imgsz=(<span class=\"number\">1</span> <span class=\"keyword\">if</span> pt <span class=\"keyword\">else</span> bs, <span class=\"number\">3</span>, *imgsz))  <span class=\"comment\"># warmup</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">identify</span>(<span class=\"params\">self, pic_path</span>):</span><br><span class=\"line\">        im0s = cv2.imread(pic_path)</span><br><span class=\"line\">        img = letterbox(im0s)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        img = img.transpose((<span class=\"number\">2</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>))[::-<span class=\"number\">1</span>]  <span class=\"comment\"># HWC to CHW, BGR to RGB</span></span><br><span class=\"line\">        im = np.ascontiguousarray(img)</span><br><span class=\"line\">        im = torch.from_numpy(im).to().<span class=\"built_in\">float</span>()</span><br><span class=\"line\">        im /= <span class=\"number\">255</span>  <span class=\"comment\"># 0 - 255 to 0.0 - 1.0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(im.shape) == <span class=\"number\">3</span>:</span><br><span class=\"line\">            im = im[<span class=\"literal\">None</span>]  <span class=\"comment\"># expand for batch dim</span></span><br><span class=\"line\"></span><br><span class=\"line\">        pred = self.model(im)</span><br><span class=\"line\">        pred = non_max_suppression(pred)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, det <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(pred):  <span class=\"comment\"># per image</span></span><br><span class=\"line\">            im0 = im0s.copy()</span><br><span class=\"line\"></span><br><span class=\"line\">            p = Path(pic_path)  <span class=\"comment\"># to Path</span></span><br><span class=\"line\">            imc = im0.copy()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(det):</span><br><span class=\"line\">                det[:, :<span class=\"number\">4</span>] = scale_coords(im.shape[<span class=\"number\">2</span>:], det[:, :<span class=\"number\">4</span>], im0.shape).<span class=\"built_in\">round</span>()</span><br><span class=\"line\">                <span class=\"keyword\">for</span> *xyxy, conf, cls <span class=\"keyword\">in</span> <span class=\"built_in\">reversed</span>(det):</span><br><span class=\"line\">                    save_file_path = Path(<span class=\"string\">r&#x27;E:\\blog\\deep_learn\\small_img_cut&#x27;</span>) / p.stem / <span class=\"string\">f&#x27;<span class=\"subst\">&#123;p.stem&#125;</span>.jpg&#x27;</span></span><br><span class=\"line\">                    save_one_box(xyxy, imc, file=save_file_path, BGR=<span class=\"literal\">True</span>)</span><br><span class=\"line\">                    <span class=\"comment\"># print([i.cpu().detach().numpy().tolist() for i in xyxy])</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> os</span><br><span class=\"line\">    test = Detect()</span><br><span class=\"line\"></span><br><span class=\"line\">    pic_list = os.listdir(<span class=\"string\">r&#x27;E:\\blog\\deep_learn\\yolov5\\data\\images&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> pic <span class=\"keyword\">in</span> pic_list:</span><br><span class=\"line\">        test.identify(<span class=\"string\">fr&#x27;E:\\blog\\deep_learn\\big_img\\&#123;pic&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>接下来需要将相同的文字都放入到一个单独的文件夹内，为了能够快速处理，可以使用一下代码实现。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter</span><br><span class=\"line\"><span class=\"keyword\">from</span> pathlib <span class=\"keyword\">import</span> Path</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> hashlib</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">FILE = Path(__file__).resolve()</span><br><span class=\"line\">ROOT = FILE.parents[<span class=\"number\">0</span>]</span><br><span class=\"line\">ROOT = Path(os.path.relpath(ROOT, Path.cwd()))</span><br><span class=\"line\">root = tkinter.Tk()</span><br><span class=\"line\">root.title(<span class=\"string\">&quot;Preview&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">num = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">image_Splicing</span>(<span class=\"params\">data</span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> big_pic <span class=\"keyword\">in</span> data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>]:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> small_pic <span class=\"keyword\">in</span> data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>]:</span><br><span class=\"line\"></span><br><span class=\"line\">            cv2.namedWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">0</span>)  <span class=\"comment\"># 创建一个名为“Face”的窗口用于显示图像</span></span><br><span class=\"line\">            cv2.moveWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">100</span>, <span class=\"number\">50</span>)  <span class=\"comment\"># 移动窗口到适当位置</span></span><br><span class=\"line\">            cv2.resizeWindow(<span class=\"string\">&#x27;Face&#x27;</span>, <span class=\"number\">350</span>, <span class=\"number\">175</span>)</span><br><span class=\"line\">            img1 = cv2.imread(<span class=\"built_in\">str</span>(big_pic))</span><br><span class=\"line\">            img2 = cv2.imread(<span class=\"built_in\">str</span>(small_pic))</span><br><span class=\"line\"></span><br><span class=\"line\">            img1 = cv2.resize(img1, (<span class=\"number\">640</span>, <span class=\"number\">640</span>))</span><br><span class=\"line\">            img2 = cv2.resize(img2, (<span class=\"number\">640</span>, <span class=\"number\">640</span>))</span><br><span class=\"line\">            new_img = np.hstack([img1, img2])</span><br><span class=\"line\">            cv2.imshow(<span class=\"string\">&#x27;Face&#x27;</span>, new_img)  <span class=\"comment\"># 显示图像</span></span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">100</span>)  <span class=\"comment\"># 设置显示时间，1000ms</span></span><br><span class=\"line\">            judge = <span class=\"built_in\">input</span>(<span class=\"string\">&#x27;是否相同：&#x27;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> judge:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(big_pic, small_pic)</span><br><span class=\"line\">                tag_pic(big_pic, small_pic)</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>].remove(big_pic)</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>].remove(small_pic)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> image_Splicing(data)</span><br><span class=\"line\"></span><br><span class=\"line\">            cv2.destroyWindow(<span class=\"string\">&#x27;Face&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_pic_list</span>():</span><br><span class=\"line\">    pic_id_list = os.listdir(Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> pic_id <span class=\"keyword\">in</span> pic_id_list:</span><br><span class=\"line\">        pic_list = os.listdir(Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span> / pic_id))</span><br><span class=\"line\">        data = &#123;<span class=\"string\">&#x27;pic_id&#x27;</span>: pic_id, <span class=\"string\">&#x27;small_pic_path&#x27;</span>: [], <span class=\"string\">&#x27;big_pic_path&#x27;</span>: []&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> pic <span class=\"keyword\">in</span> pic_list:</span><br><span class=\"line\">            pic_path = Path(ROOT / <span class=\"string\">&#x27;small_img_cut&#x27;</span> / pic_id / pic)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(pic_path.stem) &lt; <span class=\"number\">5</span>:</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;small_pic_path&#x27;</span>].append(pic_path)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                data[<span class=\"string\">&#x27;big_pic_path&#x27;</span>].append(pic_path)</span><br><span class=\"line\">        image_Splicing(data)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hash</span>():</span><br><span class=\"line\">    time12 = <span class=\"built_in\">int</span>(time.time() * <span class=\"number\">1000</span>)</span><br><span class=\"line\">    rand04 = random.randint(<span class=\"number\">1000</span>, <span class=\"number\">9999</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> md5(<span class=\"built_in\">str</span>(time12) + <span class=\"built_in\">str</span>(rand04))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">md5</span>(<span class=\"params\">*arg</span>):</span><br><span class=\"line\">    hl = hashlib.md5()</span><br><span class=\"line\">    line = <span class=\"string\">&#x27;&#x27;</span>.join(<span class=\"built_in\">list</span>(<span class=\"built_in\">map</span>(<span class=\"keyword\">lambda</span> x: <span class=\"built_in\">str</span>(x), arg)))</span><br><span class=\"line\">    hl.update(line.encode(encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> hl.hexdigest()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tag_pic</span>(<span class=\"params\">big_pic, small_pic</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> num</span><br><span class=\"line\">    path = <span class=\"string\">f&#x27;./Siamese-pytorch/datasets/images_background/pic<span class=\"subst\">&#123;num&#125;</span>&#x27;</span></span><br><span class=\"line\">    num += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(path):</span><br><span class=\"line\">        os.mkdir(path)</span><br><span class=\"line\"></span><br><span class=\"line\">    big_file = <span class=\"built_in\">open</span>(big_pic, <span class=\"string\">&quot;rb&quot;</span>)</span><br><span class=\"line\">    big_data = big_file.read()</span><br><span class=\"line\">    big_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        new_file = <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;path&#125;</span>/<span class=\"subst\">&#123;<span class=\"built_in\">hash</span>()&#125;</span>.jpg&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>)</span><br><span class=\"line\">        new_file.write(big_data)</span><br><span class=\"line\">        new_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    small_file = <span class=\"built_in\">open</span>(small_pic, <span class=\"string\">&quot;rb&quot;</span>)</span><br><span class=\"line\">    small_data = small_file.read()</span><br><span class=\"line\">    small_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        new_file = <span class=\"built_in\">open</span>(<span class=\"string\">f&quot;<span class=\"subst\">&#123;path&#125;</span>/<span class=\"subst\">&#123;<span class=\"built_in\">hash</span>()&#125;</span>.jpg&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>)</span><br><span class=\"line\">        new_file.write(small_data)</span><br><span class=\"line\">        new_file.close()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    get_pic_list()</span><br></pre></td></tr></table></figure>\n<p>运行以上代码后可以看到会显示以下图片<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4ce2aod6yj309s05raav.jpg\" alt=\"image.png\"><br>并且在控制台会有以下内容<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4ce33kqxzj302t01d0sl.jpg\" alt=\"image.png\"><br>接下来只需要动动自己那发财的小手，如果相同则输入<code>1</code>后回车，如果不相同则直接回车。 就可以看到datasets中开始保存相同的文字图片了<br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6854b5yj30ry08in12.jpg\" alt=\"image.png\"><br>接下来的开始训练，结束训练以及验证结果均可以查看大佬的github进行操作，这里直接说结果，可以看到识别准确率还是很高的</p>\n<p><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6p2ylhnj30gk0aa41t.jpg\" alt=\"image.png\"><br><img src=\"http://tva1.sinaimg.cn/large/008lIB40ly1h4d6pcl6d1j30gv09f41s.jpg\" alt=\"image.png\"></p>\n<h2 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h2><p>最后只需要将两个识别方法进行拼接，并删除掉不相关代码，即可实现识别对应问题或图形，也可通过flask来实现接口调用</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}