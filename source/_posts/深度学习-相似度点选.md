---
title: 深度学习-相似度点选
abbrlink: 18ea3d6b
date: 2022-07-08 21:17:37
tags: [python, 深度学习]
top_img: http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg
cover: http://tva1.sinaimg.cn/large/008lIB40ly1h3zu14lh49j32yo1z44qt.jpg
---

## 分析

根据提示依次点击对应文字或图形完成验证。

![1.png](http://tva1.sinaimg.cn/large/008lIB40ly1h3zumbwf57j30o60et440.jpg)

这种验证码由于按照提示顺序进行点击，故不需识别出准确的文字。本文以WPH为例子，只记录使用小图切割+YOLOV5目标识别+相似度来返回指定坐标

`url: aHR0cHM6Ly9wYXNzcG9ydC52aXAuY29tL2xvZ2luP3NyYz1odHRwcyUzQSUyRiUyRnd3dy52aXAuY29tJTJG`

## 准备工作

直接上selenium简单粗暴，从网站上下载一些图片为后续工作做准备

![2.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hicq5f7j30n50620w0.jpg)

![3.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40hizuusqj30nk056tb1.jpg)

## YOLO目标识别

### YOLO简介
下载yoloV5（[点击进入github](https://github.com/ultralytics/yolov5)），或使用`Git Bash`在指定文件夹目录下输入下面命令行获取：
```bash
git clone https://github.com/ultralytics/yolov5.git
```
下载好之后进入yolov5根目录，运行`pip install -r requirements.txt`安装环境
![4.png](http://tva1.sinaimg.cn/large/008lIB40ly1h43ypy4kryj305h0ag0v5.jpg)
> 项目文件结构简单说明：
> `data` 主要放置相关训练数据的配置文件（读取、解析等）
> `models` 放置各模型的参数配置文件
> `weights` 放置预训练模型的权重文件
> `inference` 放置预测/推理阶段的测试图片
> `runs` 放置训练过程中保留下来的一些数据（运行后自动创建）

### 图片标注
下载labelimg可视化图形标定工具（[点击下载](https://tzutalin.github.io/labelImg/)），Faster R-CNN，YOLO，SSD等目标检测网络所需要的数据集，均需要借此工具标定图像中的目标。生成的 XML 文件是遵循 PASCAL VOC 的格式的。软件打开界面如下：

{% note info %} labelimg一定要放到全英文路径下，否则会报错 {% endnote %}
软件打开界面如下：
![5.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i6f6385j30vr0madol.jpg)
软件功能介绍：
> 按键功能介绍
> 在labelImg窗口的左边功能键介绍:
> “Open”是打开单个图像，
> “Open Dir” 打开文件夹，
> "Change Save Dir" xml标注文件保存的路径，
> “Next Image” 切换到下一张图像，
> “Prev Image”切换到上一张图像，
> “Verify Image”校验图像，
> “Save”保存图像，
> “Create RectBox”画标注框一个，
> “Duplicate RectBox”重复标注框，
> “Delete RectBox”删除标注框，
> “Zoom In” 放大图像，
> “Zoom Out” 缩小图像，
> “Fit Window”图像适用窗口，
> “Fit Width”图像适应宽度。
> 一组快捷键：
> ![6.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40i8py03vj30jd0ddwhx.jpg)
> 过程
> 一般操作的顺序：单张图片的：
> “open file ” -----"create rectbox " -----"输入类别名称 "-----“change save dir ”-----"Save"
> 如果多张图片可以open dir先打开一个文件夹，然后change save dir 选择需要存储的文件夹，其余操作如上，保存后即可Next Image跳下一张。
> 最后在保存文件的路径下生成.xml文件，.xml文件的名字是和标注照片的名字一样，如果要修改已经标注过的图像，.xml中的信息也会随之改变。
> 得到的.xml 和PASCAL VOC所用格式相同。

下图则是标记好的实例数据，这里我将所有的文字都标记成了同一个label
![7.png](http://tva1.sinaimg.cn/large/008lIB40ly1h40zkqhjsvj30fx0ui7c7.jpg)


### 数据集制作
#### 图片数据集
- 将所有的图片放到`JPEGImages`文件夹下，在根目录下创建make_txt.py文件，代码如下，运行代码后`ImageSets`中生成数据集分类txt文件
```python
import os
import random
trainval_percent = 0.1
train_percent = 0.9
xmlfilepath = 'data/Annotations'
txtsavepath = 'data/ImageSets'
total_xml = os.listdir(xmlfilepath)
num = len(total_xml)
list = range(num)
tv = int(num * trainval_percent)
tr = int(tv * train_percent)
trainval = random.sample(list, tv)
train = random.sample(trainval, tr)
ftrainval = open('data/ImageSets/trainval.txt', 'w')
ftest = open('data/ImageSets/test.txt', 'w')
ftrain = open('data/ImageSets/train.txt', 'w')
fval = open('data/ImageSets/val.txt', 'w')
for i in list:
    name = total_xml[i][:-4] + '\n'
    if i in trainval:
        ftrainval.write(name)
        if i in train:
            ftest.write(name)
        else:
            fval.write(name)
    else:
        ftrain.write(name)
ftrainval.close()
ftrain.close()
fval.close()
ftest.close()
```
{% note info no-icon %}
运行完成后会在ImageSets中看到做好的数据集分类
{% endnote %}
![8.png](http://tva1.sinaimg.cn/large/008lIB40ly1h443bznu3lj303f02rglu.jpg)
#### 标记数据集
- 将所有个pascal-voc格式的xml文件放入到Annotations文件夹下，根目录下创建 voc_label.py 文件，代码如下。需要注意的是，sets中改为你的sets的名字（make_txt生成的） classes修改为你需要检测的类别，在本案例中，我们只需要检测一种类别
```python
import xml.etree.ElementTree as ET
import os
from os import getcwd

sets = ['train', 'test', 'val']
classes = ['1']


def convert(size, box):
    dw = 1. / size[0]
    dh = 1. / size[1]
    x = (box[0] + box[1]) / 2.0
    y = (box[2] + box[3]) / 2.0
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    return x, y, w, h


def convert_annotation(image_id):
    in_file = open('data/Annotations/%s.xml' % image_id)
    out_file = open('data/labels/%s.txt' % image_id, 'w')
    tree = ET.parse(in_file)
    root = tree.getroot()
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)
    for obj in root.iter('object'):
        difficult = obj.find('difficult').text
        cls = obj.find('name').text
        if cls not in classes or int(difficult) == 1:
            continue
        cls_id = classes.index(cls)
        xmlbox = obj.find('bndbox')
        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),
             float(xmlbox.find('ymax').text))
        bb = convert((w, h), b)
        out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')


wd = getcwd()
print(wd)
for image_set in sets:
    if not os.path.exists('data/labels/'):
        os.makedirs('data/labels/')
    image_ids = open('data/ImageSets/%s.txt' % image_set).read().strip().split()
    list_file = open('data/%s.txt' % image_set, 'w')
    for image_id in image_ids:
        list_file.write('data/images/%s.png\n' % image_id)
        convert_annotation(image_id)
    list_file.close()
```
{% note info no-icon %}
运行完成后会在data/label中看到做好的标签文件，并且在data文件下出现了train、val、test的txt文件，保存了图片的路径
{% endnote %}
![9.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4459bvkr4j30qa04vwkk.jpg)
![10.png](http://tva1.sinaimg.cn/large/008lIB40ly1h445a78m6kj302q01rmx5.jpg)

至此我们训练前期的准备工作差不多已经做完了
### 调整参数
接下来需要简单的修改一下配置，就可以开始我们的训练了
1. 进入到data文件下，修改coco.yaml文件

![11.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4493scqutj30nx030jun.jpg)
- `path` 为train.txt 、 val.txt与test.txt所在的路径，绝对路径与相对路径均可

![12.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4495wnn78j306o01sgly.jpg)
- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改
- `names` 把所有标记的种类写入进来

2. 进入models文件夹，修改五个模型中任意即可

![13.png](http://tva1.sinaimg.cn/large/008lIB40ly1h44993v12ij303702qt91.jpg)
- `nc` 为标记种类数，这里我们按照实际标记的种类数进行修改

3. 进入根目录，修改train.py文件
![14.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46awu34mbj30qo05ngtk.jpg)
`weights`，`yaml`，`data`按照自己所需文件的路径修改即可 epochs迭代次数自己决定，我这里仅用100次进行测试 batch-size过高可能会影响电脑运行速度，还是要根据自己电脑硬件条件决定增加还是减少 修改完成，运行即可！
   

### 开始训练
激动人心的时刻即将到来，在yolov5根目录运行`python  train.py`，即可看到训练已经开始了。如果运行异常，则需要反查自己的环境以及配置的路径是否有误。
![15.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46e9u1ervj30u10c6nc1.jpg)

训练程序正常后可以在根目录运行`tensorboard --logdir runs/train`， 然后在浏览器打开`localhost:6006`观察，效果如下
![16.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46egunvn4j30sj0jvdln.jpg)

### 结束训练
漫长的等待之后，训练结束
![17.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gw2qzdjj30uh07ik0c.jpg)
可以看到文件夹里躺着训练结果
![18.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gyatsmpj30s208o0y2.jpg)
weights里面静静躺着训练出的模型文件
![19.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46gzrer13j30h501gq39.jpg)

### 验证结果
训练结束之后就需要测试我们的模型识别成功率如何，使用根目录下`detect.py`文件来测试，但是还需要指定一些内容，有以下几种方式可以实现
1. 命令行运行
```bash
python detect.py --weights runs/train/exp17/weights/best.pt --source data/Samples/ --device cpu
```
> `weights` 为最终训练出来的模型
> `source` 为测试图片存放位置
> `device` 为加载模型使用的设备
2. pycharm中指定参数
![20.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jjh1ykgj30pk0epq7m.jpg)
> 在pycharm的配置中添加参数，直接运行即可

运行结束后会在`yolov5\runs\detect`路径中查看识别结果，可以看到识别准确率还是非常高的，至此我们的目标识别这一部分就做完了
![21.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46jx9pmlpj30i903ywgj.jpg)

## 小图切割
当大图的训练结束之后，则需要处理小图了。在大量观察后发现小图均有一定的规律，提示要点击的文字均处在同一位置上，那么我们就可以通过最简单的方法：直接指定像素进行图片切割来快速提取出来需要点击的文字
![22.png](http://tva1.sinaimg.cn/large/008lIB40ly1h46kmrmjjxj30q409q462.jpg)
```python
from PIL import Image
import os


def splitimage(img):
    # 小图切割
    coordinates_list = [149, 192, 235]  # 需要切割的像素位置
    result = list()
    for index, x in enumerate(coordinates_list):
        box = (x, 1, x + 26, 28)
        small_pic = img.crop(box)
        result.append(small_pic)
    return result


big_img_dir = r'.\yolov5\data\images'  # 大图所在路径
yolo_img_list = os.listdir(big_img_dir)

for img_name in yolo_img_list:
    print(img_name)

    img_name = img_name.split('.')[0]
    cut_img_list = splitimage(Image.open(fr'small_img/{img_name}.png'))  # 与大图对应的小图进行切割
    if not os.path.exists(f'./small_img_cut/{img_name}'):
        os.makedirs(f'./small_img_cut/{img_name}')

    for index, cut_img in enumerate(cut_img_list):
        cut_img.save(f'./small_img_cut/{img_name}/{index}.png')  # 切割后图片保存
```
运行结束后可以看到每个小图已经切割成功，并单独存入单独的文件夹内
![23.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eihrabnj30860c778e.jpg)
![24.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47eisgj0lj309603rt8r.jpg)
那么这一步小图也处理完成，仅仅剩下最后一步就可以完成识别了

## 孪生网络相似度训练
### 孪生网络简介
这里就不过多介绍了，可以直接去大佬github中详细学习[点击进入](https://github.com/bubbliiiing/Siamese-keras)
### 数据集制作
这里我对yolov5中的detect.py进行了小小的改动，将识别出来的大图放入到之前切割好的小图中，方便我们后续操作
![25.png](http://tva1.sinaimg.cn/large/008lIB40ly1h47r3g7i0oj30po04rdhy.jpg)
代码如下：
```python
from pathlib import Path
import cv2
import torch
import numpy as np
from utils.augmentations import letterbox
from models.common import DetectMultiBackend
from utils.general import check_img_size, non_max_suppression, scale_coords
from utils.plots import save_one_box


class Detect:
    def __init__(self,
                 weights='weights/best.pt',  # model.pt path(s)
                 source='data/Samples',  # file/dir/URL/glob, 0 for webcam
                 data='data/coco128.yaml',  # dataset.yaml path
                 imgsz=(640, 640),  # inference size (height, width)
                 project='runs/detect',  # save results to project/name
                 ):
        self.source = str(source)
        self.weights = weights
        self.data = data
        self.imgsz = imgsz

        self.model = None

        self.save_dir = Path(project)  # increment run
        self.save_dir.mkdir(parents=True, exist_ok=True)  # make dir
        self.load_model()

    def load_model(self):
        self.model = DetectMultiBackend(self.weights, data=self.data)
        stride, names, pt = self.model.stride, self.model.names, self.model.pt
        imgsz = check_img_size(self.imgsz, s=stride)  # check image size
        bs = 1  # batch_size
        self.model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup

    def identify(self, pic_path):
        im0s = cv2.imread(pic_path)
        img = letterbox(im0s)[0]
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        im = np.ascontiguousarray(img)
        im = torch.from_numpy(im).to().float()
        im /= 255  # 0 - 255 to 0.0 - 1.0
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim

        pred = self.model(im)
        pred = non_max_suppression(pred)

        for i, det in enumerate(pred):  # per image
            im0 = im0s.copy()

            p = Path(pic_path)  # to Path
            imc = im0.copy()
            if len(det):
                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()
                for *xyxy, conf, cls in reversed(det):
                    save_file_path = Path(r'E:\blog\deep_learn\small_img_cut') / p.stem / f'{p.stem}.jpg'
                    save_one_box(xyxy, imc, file=save_file_path, BGR=True)
                    # print([i.cpu().detach().numpy().tolist() for i in xyxy])


if __name__ == '__main__':
    import os
    test = Detect()

    pic_list = os.listdir(r'E:\blog\deep_learn\yolov5\data\images')
    for pic in pic_list:
        test.identify(fr'E:\blog\deep_learn\big_img\{pic}')
```
接下来需要将相同的文字都放入到一个单独的文件夹内，为了能够快速处理，可以使用一下代码实现。
```python
import time
import tkinter
from pathlib import Path
import os
import cv2
import hashlib
import random
import numpy as np

FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))
root = tkinter.Tk()
root.title("Preview")

num = 1


def image_Splicing(data):
    for big_pic in data['big_pic_path']:
        for small_pic in data['small_pic_path']:

            cv2.namedWindow('Face', 0)  # 创建一个名为“Face”的窗口用于显示图像
            cv2.moveWindow('Face', 100, 50)  # 移动窗口到适当位置
            cv2.resizeWindow('Face', 350, 175)
            img1 = cv2.imread(str(big_pic))
            img2 = cv2.imread(str(small_pic))

            img1 = cv2.resize(img1, (640, 640))
            img2 = cv2.resize(img2, (640, 640))
            new_img = np.hstack([img1, img2])
            cv2.imshow('Face', new_img)  # 显示图像
            cv2.waitKey(100)  # 设置显示时间，1000ms
            judge = input('是否相同：')
            if judge:
                print(big_pic, small_pic)
                tag_pic(big_pic, small_pic)
                data['big_pic_path'].remove(big_pic)
                data['small_pic_path'].remove(small_pic)
                return image_Splicing(data)

            cv2.destroyWindow('Face')


def get_pic_list():
    pic_id_list = os.listdir(Path(ROOT / 'small_img_cut'))
    for pic_id in pic_id_list:
        pic_list = os.listdir(Path(ROOT / 'small_img_cut' / pic_id))
        data = {'pic_id': pic_id, 'small_pic_path': [], 'big_pic_path': []}
        for pic in pic_list:
            pic_path = Path(ROOT / 'small_img_cut' / pic_id / pic)
            if len(pic_path.stem) < 5:
                data['small_pic_path'].append(pic_path)
            else:
                data['big_pic_path'].append(pic_path)
        image_Splicing(data)


def hash():
    time12 = int(time.time() * 1000)
    rand04 = random.randint(1000, 9999)
    return md5(str(time12) + str(rand04))


def md5(*arg):
    hl = hashlib.md5()
    line = ''.join(list(map(lambda x: str(x), arg)))
    hl.update(line.encode(encoding='utf-8'))
    return hl.hexdigest()


def tag_pic(big_pic, small_pic):
    global num
    path = f'./Siamese-pytorch/datasets/images_background/pic{num}'
    num += 1
    if not os.path.exists(path):
        os.mkdir(path)

    big_file = open(big_pic, "rb")
    big_data = big_file.read()
    big_file.close()

    for i in range(5):
        new_file = open(f"{path}/{hash()}.jpg", "wb")
        new_file.write(big_data)
        new_file.close()

    small_file = open(small_pic, "rb")
    small_data = small_file.read()
    small_file.close()

    for i in range(5):
        new_file = open(f"{path}/{hash()}.jpg", "wb")
        new_file.write(small_data)
        new_file.close()


if __name__ == '__main__':
    get_pic_list()
```
运行以上代码后可以看到会显示以下图片
![26.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce2aod6yj309s05raav.jpg)
并且在控制台会有以下内容
![27.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4ce33kqxzj302t01d0sl.jpg)
接下来只需要动动自己那发财的小手，如果相同则输入`1`后回车，如果不相同则直接回车。 就可以看到datasets中开始保存相同的文字图片了
![28.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6854b5yj30ry08in12.jpg)
接下来的开始训练，结束训练以及验证结果均可以查看大佬的github进行操作，这里直接说结果，可以看到识别准确率还是很高的

![29.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6p2ylhnj30gk0aa41t.jpg)
![30.png](http://tva1.sinaimg.cn/large/008lIB40ly1h4d6pcl6d1j30gv09f41s.jpg)
## 结尾
最后只需要将两个识别方法进行拼接，并删除掉不相关代码，即可实现识别对应问题或图形，也可通过flask来实现接口调用